
==> Audit <==
|---------|---------------------|----------|----------|---------|---------------------|---------------------|
| Command |        Args         | Profile  |   User   | Version |     Start Time      |      End Time       |
|---------|---------------------|----------|----------|---------|---------------------|---------------------|
| start   |                     | minikube | mohammed | v1.35.0 | 24 Jan 25 11:07 CET | 24 Jan 25 11:42 CET |
| kubectl | get po              | minikube | mohammed | v1.35.0 | 24 Jan 25 11:43 CET |                     |
| start   | --driver=docker     | minikube | mohammed | v1.35.0 | 12 Feb 25 23:09 CET |                     |
| start   | --driver=virtualbox | minikube | mohammed | v1.35.0 | 12 Feb 25 23:09 CET |                     |
| start   | --driver=docker     | minikube | mohammed | v1.35.0 | 12 Feb 25 23:30 CET |                     |
| start   | --driver=virtuabox  | minikube | mohammed | v1.35.0 | 12 Feb 25 23:30 CET |                     |
| start   | --driver=virtualbox | minikube | mohammed | v1.35.0 | 12 Feb 25 23:30 CET | 13 Feb 25 09:32 CET |
| start   |                     | minikube | mohammed | v1.35.0 | 12 Mar 25 12:49 CET |                     |
| start   |                     | minikube | mohammed | v1.35.0 | 12 Mar 25 12:56 CET | 12 Mar 25 13:05 CET |
| addons  | enable ingress      | minikube | mohammed | v1.35.0 | 12 Mar 25 14:11 CET |                     |
| addons  | enable ingress      | minikube | mohammed | v1.35.0 | 12 Mar 25 14:21 CET |                     |
|---------|---------------------|----------|----------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2025/03/12 12:56:52
Running on machine: pop-os
Binary: Built with gc go1.23.4 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0312 12:56:52.457224    5622 out.go:345] Setting OutFile to fd 1 ...
I0312 12:56:52.459000    5622 out.go:397] isatty.IsTerminal(1) = true
I0312 12:56:52.459042    5622 out.go:358] Setting ErrFile to fd 2...
I0312 12:56:52.459116    5622 out.go:397] isatty.IsTerminal(2) = true
I0312 12:56:52.461506    5622 root.go:338] Updating PATH: /home/mohammed/.minikube/bin
I0312 12:56:52.474946    5622 out.go:352] Setting JSON to false
I0312 12:56:52.487379    5622 start.go:129] hostinfo: {"hostname":"pop-os","uptime":234,"bootTime":1741780378,"procs":249,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"bookworm/sid","kernelVersion":"6.12.10-76061203-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"555c040d-5322-0935-7cb3-2548666da025"}
I0312 12:56:52.488454    5622 start.go:139] virtualization: kvm host
I0312 12:56:52.497378    5622 out.go:177] üòÑ  minikube v1.35.0 on Debian bookworm/sid
I0312 12:56:52.508656    5622 notify.go:220] Checking for updates...
I0312 12:56:52.513384    5622 config.go:182] Loaded profile config "minikube": Driver=virtualbox, ContainerRuntime=docker, KubernetesVersion=v1.32.0
I0312 12:56:52.517115    5622 driver.go:394] Setting default libvirt URI to qemu:///system
I0312 12:56:53.012391    5622 virtualbox.go:136] virtual box version: 7.0.18_Ubuntur162988
I0312 12:56:53.020511    5622 out.go:177] ‚ú®  Using the virtualbox driver based on existing profile
I0312 12:56:53.026594    5622 start.go:297] selected driver: virtualbox
I0312 12:56:53.026640    5622 start.go:901] validating driver "virtualbox" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.35.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:virtualbox HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mohammed:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0312 12:56:53.027405    5622 start.go:912] status for virtualbox: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:7.0.18_Ubuntur162988
}
I0312 12:56:53.043564    5622 cni.go:84] Creating CNI manager for ""
I0312 12:56:53.044057    5622 cni.go:158] "virtualbox" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0312 12:56:53.047643    5622 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.35.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:virtualbox HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mohammed:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0312 12:56:53.048962    5622 iso.go:125] acquiring lock: {Name:mkdb2d61536ae97e8418bcae9e92a6ccdb3989e8 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0312 12:56:53.057402    5622 out.go:177] üëç  Starting "minikube" primary control-plane node in "minikube" cluster
I0312 12:56:53.062763    5622 preload.go:131] Checking if preload exists for k8s version v1.32.0 and runtime docker
I0312 12:56:53.063022    5622 preload.go:146] Found local preload: /home/mohammed/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.32.0-docker-overlay2-amd64.tar.lz4
I0312 12:56:53.063062    5622 cache.go:56] Caching tarball of preloaded images
I0312 12:56:53.064700    5622 preload.go:172] Found /home/mohammed/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.32.0-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0312 12:56:53.064797    5622 cache.go:59] Finished verifying existence of preloaded tar for v1.32.0 on docker
I0312 12:56:53.065542    5622 profile.go:143] Saving config to /home/mohammed/.minikube/profiles/minikube/config.json ...
I0312 12:56:53.067470    5622 start.go:360] acquireMachinesLock for minikube: {Name:mk0b9d8f747af292d177c2c5e5cad545b6722152 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I0312 12:56:53.068030    5622 start.go:364] duration metric: took 446.035¬µs to acquireMachinesLock for "minikube"
I0312 12:56:53.068129    5622 start.go:96] Skipping create...Using existing machine configuration
I0312 12:56:53.068198    5622 fix.go:54] fixHost starting: 
I0312 12:56:53.070608    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:56:55.457032    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="aborted"
VMStateChangeTime="2025-03-12T11:50:26.000000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
}
I0312 12:56:55.457142    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:56:55.457655    5622 fix.go:112] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0312 12:56:55.457749    5622 fix.go:138] unexpected machine state, will restart: <nil>
I0312 12:56:55.465066    5622 out.go:177] üîÑ  Restarting existing virtualbox VM for "minikube" ...
I0312 12:56:55.468833    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:56:57.219954    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="aborted"
VMStateChangeTime="2025-03-12T11:50:26.000000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
}
I0312 12:56:57.220358    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:56:57.222901    5622 main.go:141] libmachine: Check network to re-create if needed...
I0312 12:56:57.223353    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage list hostonlyifs
I0312 12:56:58.098382    5622 main.go:141] libmachine: STDOUT:
{
Name:            vboxnet0
GUID:            786f6276-656e-4074-8000-0a0027000000
DHCP:            Disabled
IPAddress:       192.168.59.1
NetworkMask:     255.255.255.0
IPV6Address:     
IPV6NetworkMaskPrefixLength: 0
HardwareAddress: 0a:00:27:00:00:00
MediumType:      Ethernet
Wireless:        No
Status:          Down
VBoxNetworkName: HostInterfaceNetworking-vboxnet0

}
I0312 12:56:58.098471    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:56:58.102915    5622 main.go:141] libmachine: Searching for hostonly interface for IPv4: 192.168.59.1 and Mask: ffffff00
I0312 12:56:58.102989    5622 main.go:141] libmachine: Found: vboxnet0
I0312 12:56:58.103085    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage list dhcpservers
I0312 12:56:58.857969    5622 main.go:141] libmachine: STDOUT:
{
NetworkName:    HostInterfaceNetworking-vboxnet0
Dhcpd IP:       192.168.59.16
LowerIPAddress: 192.168.59.100
UpperIPAddress: 192.168.59.254
NetworkMask:    255.255.255.0
Enabled:        Yes
Global Configuration:
    minLeaseTime:     default
    defaultLeaseTime: default
    maxLeaseTime:     default
    Forced options:   None
    Suppressed opts.: None
        1/legacy: 255.255.255.0
Groups:               None
Individual Configs:   None
}
I0312 12:56:58.858033    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:56:58.858560    5622 main.go:141] libmachine: Removing orphan DHCP servers...
I0312 12:56:58.858704    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage list hostonlyifs
I0312 12:56:59.987070    5622 main.go:141] libmachine: STDOUT:
{
Name:            vboxnet0
GUID:            786f6276-656e-4074-8000-0a0027000000
DHCP:            Disabled
IPAddress:       192.168.59.1
NetworkMask:     255.255.255.0
IPV6Address:     
IPV6NetworkMaskPrefixLength: 0
HardwareAddress: 0a:00:27:00:00:00
MediumType:      Ethernet
Wireless:        No
Status:          Down
VBoxNetworkName: HostInterfaceNetworking-vboxnet0

}
I0312 12:56:59.987308    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:56:59.988776    5622 main.go:141] libmachine: Adding/Modifying DHCP server "192.168.59.22" with address range "192.168.59.100" - "192.168.59.254"...
I0312 12:56:59.988994    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage list dhcpservers
I0312 12:57:00.536483    5622 main.go:141] libmachine: STDOUT:
{
NetworkName:    HostInterfaceNetworking-vboxnet0
Dhcpd IP:       192.168.59.16
LowerIPAddress: 192.168.59.100
UpperIPAddress: 192.168.59.254
NetworkMask:    255.255.255.0
Enabled:        Yes
Global Configuration:
    minLeaseTime:     default
    defaultLeaseTime: default
    maxLeaseTime:     default
    Forced options:   None
    Suppressed opts.: None
        1/legacy: 255.255.255.0
Groups:               None
Individual Configs:   None
}
I0312 12:57:00.536705    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:57:00.539152    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage dhcpserver modify --netname HostInterfaceNetworking-vboxnet0 --ip 192.168.59.22 --netmask 255.255.255.0 --lowerip 192.168.59.100 --upperip 192.168.59.254 --enable
I0312 12:57:01.266222    5622 main.go:141] libmachine: STDOUT:
{
}
I0312 12:57:01.266463    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:57:01.266792    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage modifyvm minikube --nic2 hostonly --nictype2 virtio --nicpromisc2 deny --hostonlyadapter2 vboxnet0 --cableconnected2 on
I0312 12:57:02.370968    5622 main.go:141] libmachine: STDOUT:
{
}
I0312 12:57:02.371026    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:57:02.372366    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage modifyvm minikube --natpf1 delete ssh
I0312 12:57:02.899744    5622 main.go:141] libmachine: STDOUT:
{
}
I0312 12:57:02.899803    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:57:02.899911    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage modifyvm minikube --natpf1 ssh,tcp,127.0.0.1,39961,,22
I0312 12:57:03.664893    5622 main.go:141] libmachine: STDOUT:
{
}
I0312 12:57:03.665092    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:57:03.665180    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage startvm minikube --type headless
I0312 12:57:09.028524    5622 main.go:141] libmachine: STDOUT:
{
Waiting for VM "minikube" to power on...
VM "minikube" has been successfully started.
}
I0312 12:57:09.029808    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:57:09.030610    5622 main.go:141] libmachine: Checking vm logs: /home/mohammed/.minikube/machines/minikube/minikube/Logs/VBox.log
I0312 12:57:09.048875    5622 main.go:141] libmachine: Waiting for an IP...
I0312 12:57:09.048941    5622 main.go:141] libmachine: Getting to WaitForSSH function...
I0312 12:57:09.051048    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:57:09.057490    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:57:09.057568    5622 main.go:141] libmachine: About to run SSH command:
exit 0
I0312 12:58:24.396315    5622 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:48886->127.0.0.1:39961: read: connection reset by peer
I0312 12:59:22.134841    5622 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:54150->127.0.0.1:39961: read: connection reset by peer
I0312 12:59:27.008720    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0312 12:59:27.008832    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:28.478188    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:28.478325    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:28.479349    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:30.053746    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:30.053946    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:30.057305    5622 main.go:141] libmachine: Host-only MAC: 080027210068

I0312 12:59:30.057689    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:30.059222    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:30.059393    5622 main.go:141] libmachine: About to run SSH command:
ip addr show
I0312 12:59:31.217675    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86383sec preferred_lft 86383sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 583sec preferred_lft 583sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

I0312 12:59:31.218514    5622 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86383sec preferred_lft 86383sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 583sec preferred_lft 583sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

END SSH

I0312 12:59:31.218637    5622 main.go:141] libmachine: IP is 192.168.59.100
I0312 12:59:31.218736    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:32.385394    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:32.385555    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:32.386458    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:33.595734    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:33.595815    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:33.597854    5622 main.go:141] libmachine: Host-only MAC: 080027210068

I0312 12:59:33.598160    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:33.599772    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:33.599845    5622 main.go:141] libmachine: About to run SSH command:
ip addr show
I0312 12:59:34.283332    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86380sec preferred_lft 86380sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 580sec preferred_lft 580sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

I0312 12:59:34.283696    5622 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86380sec preferred_lft 86380sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 580sec preferred_lft 580sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

END SSH

I0312 12:59:34.283822    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage list hostonlyifs
I0312 12:59:34.739691    5622 main.go:141] libmachine: STDOUT:
{
Name:            vboxnet0
GUID:            786f6276-656e-4074-8000-0a0027000000
DHCP:            Disabled
IPAddress:       192.168.59.1
NetworkMask:     255.255.255.0
IPV6Address:     fe80::800:27ff:fe00:0
IPV6NetworkMaskPrefixLength: 64
HardwareAddress: 0a:00:27:00:00:00
MediumType:      Ethernet
Wireless:        No
Status:          Up
VBoxNetworkName: HostInterfaceNetworking-vboxnet0

}
I0312 12:59:34.739779    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:34.742983    5622 main.go:141] libmachine: Found: vboxnet0
I0312 12:59:34.745493    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:35.913967    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:35.914120    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:35.914836    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:37.086840    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:37.086917    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:37.090162    5622 main.go:141] libmachine: Host-only MAC: 080027210068

I0312 12:59:37.090556    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:37.092342    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:37.092420    5622 main.go:141] libmachine: About to run SSH command:
ip addr show
I0312 12:59:37.744671    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86377sec preferred_lft 86377sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 577sec preferred_lft 577sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

I0312 12:59:37.745045    5622 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86377sec preferred_lft 86377sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 577sec preferred_lft 577sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

END SSH

I0312 12:59:37.745755    5622 profile.go:143] Saving config to /home/mohammed/.minikube/profiles/minikube/config.json ...
I0312 12:59:37.747995    5622 machine.go:93] provisionDockerMachine start ...
I0312 12:59:37.748603    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:37.750009    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:37.750077    5622 main.go:141] libmachine: About to run SSH command:
hostname
I0312 12:59:38.437597    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0312 12:59:38.437665    5622 buildroot.go:166] provisioning hostname "minikube"
I0312 12:59:38.438818    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:38.440479    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:38.440607    5622 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0312 12:59:39.365242    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0312 12:59:39.365980    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:39.367490    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:39.367663    5622 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0312 12:59:40.025494    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0312 12:59:40.025683    5622 buildroot.go:172] set auth options {CertDir:/home/mohammed/.minikube CaCertPath:/home/mohammed/.minikube/certs/ca.pem CaPrivateKeyPath:/home/mohammed/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/mohammed/.minikube/machines/server.pem ServerKeyPath:/home/mohammed/.minikube/machines/server-key.pem ClientKeyPath:/home/mohammed/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/mohammed/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/mohammed/.minikube}
I0312 12:59:40.025863    5622 buildroot.go:174] setting up certificates
I0312 12:59:40.025916    5622 provision.go:84] configureAuth start
I0312 12:59:40.026050    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:41.194458    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:41.194571    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:41.195071    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 12:59:42.360655    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 12:59:42.360727    5622 main.go:141] libmachine: STDERR:
{
}
I0312 12:59:42.362506    5622 main.go:141] libmachine: Host-only MAC: 080027210068

I0312 12:59:42.362919    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:42.364494    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:42.364559    5622 main.go:141] libmachine: About to run SSH command:
ip addr show
I0312 12:59:43.052891    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86372sec preferred_lft 86372sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 572sec preferred_lft 572sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

I0312 12:59:43.053633    5622 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86372sec preferred_lft 86372sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 572sec preferred_lft 572sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0

END SSH

I0312 12:59:43.053722    5622 provision.go:143] copyHostCerts
I0312 12:59:43.054653    5622 exec_runner.go:144] found /home/mohammed/.minikube/cert.pem, removing ...
I0312 12:59:43.054709    5622 exec_runner.go:203] rm: /home/mohammed/.minikube/cert.pem
I0312 12:59:43.055089    5622 exec_runner.go:151] cp: /home/mohammed/.minikube/certs/cert.pem --> /home/mohammed/.minikube/cert.pem (1127 bytes)
I0312 12:59:43.057467    5622 exec_runner.go:144] found /home/mohammed/.minikube/key.pem, removing ...
I0312 12:59:43.057516    5622 exec_runner.go:203] rm: /home/mohammed/.minikube/key.pem
I0312 12:59:43.057804    5622 exec_runner.go:151] cp: /home/mohammed/.minikube/certs/key.pem --> /home/mohammed/.minikube/key.pem (1679 bytes)
I0312 12:59:43.059676    5622 exec_runner.go:144] found /home/mohammed/.minikube/ca.pem, removing ...
I0312 12:59:43.059731    5622 exec_runner.go:203] rm: /home/mohammed/.minikube/ca.pem
I0312 12:59:43.060041    5622 exec_runner.go:151] cp: /home/mohammed/.minikube/certs/ca.pem --> /home/mohammed/.minikube/ca.pem (1082 bytes)
I0312 12:59:43.061688    5622 provision.go:117] generating server cert: /home/mohammed/.minikube/machines/server.pem ca-key=/home/mohammed/.minikube/certs/ca.pem private-key=/home/mohammed/.minikube/certs/ca-key.pem org=mohammed.minikube san=[127.0.0.1 192.168.59.100 localhost minikube]
I0312 12:59:44.231789    5622 provision.go:177] copyRemoteCerts
I0312 12:59:44.233181    5622 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0312 12:59:44.233344    5622 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:39961 SSHKeyPath:/home/mohammed/.minikube/machines/minikube/id_rsa Username:docker}
I0312 12:59:44.731561    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0312 12:59:45.163044    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/machines/server.pem --> /etc/docker/server.pem (1184 bytes)
I0312 12:59:45.592967    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0312 12:59:46.037184    5622 provision.go:87] duration metric: took 6.011212174s to configureAuth
I0312 12:59:46.037333    5622 buildroot.go:189] setting minikube options for container-runtime
I0312 12:59:46.038467    5622 config.go:182] Loaded profile config "minikube": Driver=virtualbox, ContainerRuntime=docker, KubernetesVersion=v1.32.0
I0312 12:59:46.038807    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:46.042191    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:46.042349    5622 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0312 12:59:46.775898    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: tmpfs

I0312 12:59:46.775950    5622 buildroot.go:70] root file system type: tmpfs
I0312 12:59:46.776696    5622 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0312 12:59:46.777039    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:46.779151    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:46.779924    5622 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=virtualbox --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0312 12:59:47.719755    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=virtualbox --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0312 12:59:47.720146    5622 main.go:141] libmachine: Using SSH client type: native
I0312 12:59:47.722663    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 12:59:47.722817    5622 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0312 13:00:08.964668    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: diff: can't stat '/lib/systemd/system/docker.service': No such file or directory
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service ‚Üí /usr/lib/systemd/system/docker.service.

I0312 13:00:08.964745    5622 machine.go:96] duration metric: took 31.216701245s to provisionDockerMachine
I0312 13:00:08.964805    5622 start.go:293] postStartSetup for "minikube" (driver="virtualbox")
I0312 13:00:08.964891    5622 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0312 13:00:08.965348    5622 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0312 13:00:08.965429    5622 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:39961 SSHKeyPath:/home/mohammed/.minikube/machines/minikube/id_rsa Username:docker}
I0312 13:00:09.475540    5622 ssh_runner.go:195] Run: cat /etc/os-release
I0312 13:00:09.535734    5622 info.go:137] Remote host: Buildroot 2023.02.9
I0312 13:00:09.535823    5622 filesync.go:126] Scanning /home/mohammed/.minikube/addons for local assets ...
I0312 13:00:09.536538    5622 filesync.go:126] Scanning /home/mohammed/.minikube/files for local assets ...
I0312 13:00:09.537518    5622 start.go:296] duration metric: took 572.666066ms for postStartSetup
I0312 13:00:09.537612    5622 fix.go:56] duration metric: took 3m16.46941593s for fixHost
I0312 13:00:09.537934    5622 main.go:141] libmachine: Using SSH client type: native
I0312 13:00:09.539345    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 13:00:09.539409    5622 main.go:141] libmachine: About to run SSH command:
date +%s.%N
I0312 13:00:10.240753    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 1741780810.233034223

I0312 13:00:10.240812    5622 fix.go:216] guest clock: 1741780810.233034223
I0312 13:00:10.240869    5622 fix.go:229] Guest: 2025-03-12 13:00:10.233034223 +0100 CET Remote: 2025-03-12 13:00:09.537627254 +0100 CET m=+198.040917801 (delta=695.406969ms)
I0312 13:00:10.241106    5622 fix.go:200] guest clock delta is within tolerance: 695.406969ms
I0312 13:00:10.241148    5622 start.go:83] releasing machines lock for "minikube", held for 3m17.173065667s
I0312 13:00:10.241396    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 13:00:11.427878    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 13:00:11.427962    5622 main.go:141] libmachine: STDERR:
{
}
I0312 13:00:11.428736    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 13:00:12.641081    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 13:00:12.641180    5622 main.go:141] libmachine: STDERR:
{
}
I0312 13:00:12.644937    5622 main.go:141] libmachine: Host-only MAC: 080027210068

I0312 13:00:12.645320    5622 main.go:141] libmachine: Using SSH client type: native
I0312 13:00:12.646984    5622 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 39961 <nil> <nil>}
I0312 13:00:12.647077    5622 main.go:141] libmachine: About to run SSH command:
ip addr show
I0312 13:00:13.370159    5622 main.go:141] libmachine: SSH cmd err, output: <nil>: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86341sec preferred_lft 86341sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 541sec preferred_lft 541sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:9c:a2:b6:c5 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever

I0312 13:00:13.371081    5622 main.go:141] libmachine: SSH returned: 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:f5:ca:92 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 1024 brd 10.0.2.255 scope global dynamic eth0
       valid_lft 86341sec preferred_lft 86341sec
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:21:00:68 brd ff:ff:ff:ff:ff:ff
    inet 192.168.59.100/24 metric 1024 brd 192.168.59.255 scope global dynamic eth1
       valid_lft 541sec preferred_lft 541sec
4: sit0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
5: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:9c:a2:b6:c5 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever

END SSH

I0312 13:00:13.378438    5622 ssh_runner.go:195] Run: cat /version.json
I0312 13:00:13.378536    5622 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:39961 SSHKeyPath:/home/mohammed/.minikube/machines/minikube/id_rsa Username:docker}
I0312 13:00:13.378767    5622 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0312 13:00:13.378972    5622 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:39961 SSHKeyPath:/home/mohammed/.minikube/machines/minikube/id_rsa Username:docker}
I0312 13:00:14.251229    5622 ssh_runner.go:195] Run: systemctl --version
I0312 13:00:14.335893    5622 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
W0312 13:00:14.419218    5622 cni.go:209] loopback cni configuration skipped: "/etc/cni/net.d/*loopback.conf*" not found
I0312 13:00:14.419843    5622 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0312 13:00:14.697144    5622 cni.go:262] disabled [/etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I0312 13:00:14.697214    5622 start.go:495] detecting cgroup driver to use...
I0312 13:00:14.697959    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0312 13:00:15.028290    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
I0312 13:00:15.222907    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0312 13:00:15.436108    5622 containerd.go:146] configuring containerd to use "cgroupfs" as cgroup driver...
I0312 13:00:15.436492    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0312 13:00:15.624995    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0312 13:00:15.831713    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0312 13:00:16.024053    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0312 13:00:16.222201    5622 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0312 13:00:16.405297    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0312 13:00:16.589025    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0312 13:00:16.783024    5622 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0312 13:00:16.964996    5622 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0312 13:00:17.140871    5622 crio.go:166] couldn't verify netfilter by "sudo sysctl net.bridge.bridge-nf-call-iptables" which might be okay. error: sudo sysctl net.bridge.bridge-nf-call-iptables: Process exited with status 255
stdout:

stderr:
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
I0312 13:00:17.141370    5622 ssh_runner.go:195] Run: sudo modprobe br_netfilter
I0312 13:00:17.327027    5622 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0312 13:00:17.577391    5622 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0312 13:00:21.472225    5622 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (3.894718871s)
I0312 13:00:21.472611    5622 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0312 13:00:21.834776    5622 start.go:495] detecting cgroup driver to use...
I0312 13:00:21.835163    5622 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0312 13:00:22.161915    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0312 13:00:22.454751    5622 ssh_runner.go:195] Run: sudo systemctl stop -f containerd
I0312 13:00:22.810514    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0312 13:00:23.086833    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0312 13:00:23.337794    5622 ssh_runner.go:195] Run: sudo systemctl stop -f crio
I0312 13:00:23.884406    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0312 13:00:24.124971    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0312 13:00:24.450588    5622 ssh_runner.go:195] Run: which cri-dockerd
I0312 13:00:24.499356    5622 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0312 13:00:24.666651    5622 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I0312 13:00:24.976714    5622 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0312 13:00:28.900604    5622 ssh_runner.go:235] Completed: sudo systemctl unmask docker.service: (3.923768087s)
I0312 13:00:28.901101    5622 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0312 13:00:32.699153    5622 ssh_runner.go:235] Completed: sudo systemctl enable docker.socket: (3.797924588s)
I0312 13:00:32.699236    5622 docker.go:574] configuring docker to use "cgroupfs" as cgroup driver...
I0312 13:00:32.699879    5622 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0312 13:00:33.026391    5622 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0312 13:00:36.891885    5622 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (3.865398015s)
I0312 13:00:36.892234    5622 ssh_runner.go:195] Run: sudo systemctl restart docker
I0312 13:00:45.572111    5622 ssh_runner.go:235] Completed: sudo systemctl restart docker: (8.679761178s)
I0312 13:00:45.572535    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0312 13:00:45.843026    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0312 13:00:46.122558    5622 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0312 13:00:49.937547    5622 ssh_runner.go:235] Completed: sudo systemctl unmask cri-docker.socket: (3.814871243s)
I0312 13:00:49.937902    5622 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0312 13:00:53.892975    5622 ssh_runner.go:235] Completed: sudo systemctl enable cri-docker.socket: (3.954963598s)
I0312 13:00:53.893396    5622 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0312 13:00:57.633297    5622 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (3.739678255s)
I0312 13:00:57.633701    5622 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0312 13:00:57.981966    5622 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0312 13:00:58.256748    5622 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0312 13:01:01.929393    5622 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (3.672447992s)
I0312 13:01:01.929767    5622 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0312 13:01:03.227924    5622 ssh_runner.go:235] Completed: sudo systemctl restart cri-docker.service: (1.297889861s)
I0312 13:01:03.228159    5622 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0312 13:01:03.229862    5622 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0312 13:01:03.333281    5622 start.go:563] Will wait 60s for crictl version
I0312 13:01:03.333707    5622 ssh_runner.go:195] Run: which crictl
I0312 13:01:03.404060    5622 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0312 13:01:04.049241    5622 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  27.4.0
RuntimeApiVersion:  v1
I0312 13:01:04.050003    5622 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0312 13:01:04.428864    5622 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0312 13:01:04.825561    5622 out.go:235] üê≥  Preparing Kubernetes v1.32.0 on Docker 27.4.0 ...
I0312 13:01:06.619371    5622 ssh_runner.go:195] Run: grep 192.168.59.1	host.minikube.internal$ /etc/hosts
I0312 13:01:06.678868    5622 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.59.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0312 13:01:06.928806    5622 kubeadm.go:883] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.35.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:virtualbox HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mohammed:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0312 13:01:06.930460    5622 preload.go:131] Checking if preload exists for k8s version v1.32.0 and runtime docker
I0312 13:01:06.930934    5622 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0312 13:01:07.263574    5622 docker.go:689] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.32.0
registry.k8s.io/kube-controller-manager:v1.32.0
registry.k8s.io/kube-scheduler:v1.32.0
registry.k8s.io/kube-proxy:v1.32.0
registry.k8s.io/etcd:3.5.16-0
registry.k8s.io/coredns/coredns:v1.11.3
registry.k8s.io/pause:3.10
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0312 13:01:07.263632    5622 docker.go:619] Images already preloaded, skipping extraction
I0312 13:01:07.263963    5622 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0312 13:01:07.607899    5622 docker.go:689] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.32.0
registry.k8s.io/kube-controller-manager:v1.32.0
registry.k8s.io/kube-scheduler:v1.32.0
registry.k8s.io/kube-proxy:v1.32.0
registry.k8s.io/etcd:3.5.16-0
registry.k8s.io/coredns/coredns:v1.11.3
registry.k8s.io/pause:3.10
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0312 13:01:07.607997    5622 cache_images.go:84] Images are preloaded, skipping loading
I0312 13:01:07.608045    5622 kubeadm.go:934] updating node { 192.168.59.100 8443 v1.32.0 docker true true} ...
I0312 13:01:07.608747    5622 kubeadm.go:946] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.32.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.59.100

[Install]
 config:
{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0312 13:01:07.609114    5622 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0312 13:01:08.462117    5622 cni.go:84] Creating CNI manager for ""
I0312 13:01:08.462556    5622 cni.go:158] "virtualbox" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0312 13:01:08.462816    5622 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0312 13:01:08.463012    5622 kubeadm.go:189] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.59.100 APIServerPort:8443 KubernetesVersion:v1.32.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.59.100"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.59.100 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0312 13:01:08.464059    5622 kubeadm.go:195] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.59.100
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    - name: "node-ip"
      value: "192.168.59.100"
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.59.100"]
  extraArgs:
    - name: "enable-admission-plugins"
      value: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    - name: "allocate-node-cidrs"
      value: "true"
    - name: "leader-elect"
      value: "false"
scheduler:
  extraArgs:
    - name: "leader-elect"
      value: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      - name: "proxy-refresh-interval"
        value: "70000"
kubernetesVersion: v1.32.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0312 13:01:08.464769    5622 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.32.0
I0312 13:01:08.680889    5622 binaries.go:44] Found k8s binaries, skipping transfer
I0312 13:01:08.681332    5622 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0312 13:01:08.887858    5622 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (309 bytes)
I0312 13:01:09.248527    5622 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0312 13:01:09.582659    5622 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2292 bytes)
I0312 13:01:09.928862    5622 ssh_runner.go:195] Run: grep 192.168.59.100	control-plane.minikube.internal$ /etc/hosts
I0312 13:01:09.994049    5622 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.59.100	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0312 13:01:10.214407    5622 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0312 13:01:14.275515    5622 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (4.06028628s)
I0312 13:01:14.278060    5622 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0312 13:01:14.640644    5622 certs.go:68] Setting up /home/mohammed/.minikube/profiles/minikube for IP: 192.168.59.100
I0312 13:01:14.640690    5622 certs.go:194] generating shared ca certs ...
I0312 13:01:14.640776    5622 certs.go:226] acquiring lock for ca certs: {Name:mk13e0a3d0976b198b2fcddc825bdfb873e80857 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0312 13:01:14.650757    5622 certs.go:235] skipping valid "minikubeCA" ca cert: /home/mohammed/.minikube/ca.key
I0312 13:01:14.654898    5622 certs.go:235] skipping valid "proxyClientCA" ca cert: /home/mohammed/.minikube/proxy-client-ca.key
I0312 13:01:14.655009    5622 certs.go:256] generating profile certs ...
I0312 13:01:14.656638    5622 certs.go:359] skipping valid signed profile cert regeneration for "minikube-user": /home/mohammed/.minikube/profiles/minikube/client.key
I0312 13:01:14.657995    5622 certs.go:359] skipping valid signed profile cert regeneration for "minikube": /home/mohammed/.minikube/profiles/minikube/apiserver.key.0d501952
I0312 13:01:14.659052    5622 certs.go:359] skipping valid signed profile cert regeneration for "aggregator": /home/mohammed/.minikube/profiles/minikube/proxy-client.key
I0312 13:01:14.660821    5622 certs.go:484] found cert: /home/mohammed/.minikube/certs/ca-key.pem (1675 bytes)
I0312 13:01:14.661221    5622 certs.go:484] found cert: /home/mohammed/.minikube/certs/ca.pem (1082 bytes)
I0312 13:01:14.666533    5622 certs.go:484] found cert: /home/mohammed/.minikube/certs/cert.pem (1127 bytes)
I0312 13:01:14.666994    5622 certs.go:484] found cert: /home/mohammed/.minikube/certs/key.pem (1679 bytes)
I0312 13:01:14.675082    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0312 13:01:15.274964    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0312 13:01:15.917730    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0312 13:01:16.731419    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0312 13:01:17.472165    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I0312 13:01:18.218329    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0312 13:01:18.854409    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0312 13:01:19.462612    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0312 13:01:20.105731    5622 ssh_runner.go:362] scp /home/mohammed/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0312 13:01:20.732402    5622 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0312 13:01:21.099365    5622 ssh_runner.go:195] Run: openssl version
I0312 13:01:21.196733    5622 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0312 13:01:21.428700    5622 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0312 13:01:21.539354    5622 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Jan 24 10:33 /usr/share/ca-certificates/minikubeCA.pem
I0312 13:01:21.539742    5622 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0312 13:01:21.656759    5622 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0312 13:01:21.986106    5622 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0312 13:01:22.071078    5622 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0312 13:01:22.193173    5622 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0312 13:01:22.315796    5622 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0312 13:01:22.439422    5622 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0312 13:01:22.569375    5622 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0312 13:01:22.698392    5622 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0312 13:01:22.819716    5622 kubeadm.go:392] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.35.0-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:virtualbox HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/mohammed:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0312 13:01:22.820476    5622 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0312 13:01:23.221757    5622 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0312 13:01:23.457373    5622 kubeadm.go:408] found existing configuration files, will attempt cluster restart
I0312 13:01:23.457423    5622 kubeadm.go:593] restartPrimaryControlPlane start ...
I0312 13:01:23.457786    5622 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0312 13:01:23.744201    5622 kubeadm.go:130] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0312 13:01:23.751431    5622 kubeconfig.go:125] found "minikube" server: "https://192.168.59.100:8443"
I0312 13:01:23.802867    5622 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0312 13:01:24.037541    5622 kubeadm.go:630] The running cluster does not require reconfiguration: 192.168.59.100
I0312 13:01:24.037632    5622 kubeadm.go:1160] stopping kube-system containers ...
I0312 13:01:24.037966    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0312 13:01:24.551950    5622 docker.go:483] Stopping containers: [c68df857a62e a6516a9206ef 7232dfcb4106 716ead16b19e c24acc925467 0b9ee0c29ff2 382239b31e68 d9ef18715fd6 a983eec2b36c b4dc10883aec 0379962d29b0 ee731881b56d b5f6cb45bea2 5095edb46a33 5e8bea03e3db eee621a64e0c 7fa2976fc92f 75b94df5abb8 e1a8651e660a c2ef9370c561 005d77857de9]
I0312 13:01:24.552443    5622 ssh_runner.go:195] Run: docker stop c68df857a62e a6516a9206ef 7232dfcb4106 716ead16b19e c24acc925467 0b9ee0c29ff2 382239b31e68 d9ef18715fd6 a983eec2b36c b4dc10883aec 0379962d29b0 ee731881b56d b5f6cb45bea2 5095edb46a33 5e8bea03e3db eee621a64e0c 7fa2976fc92f 75b94df5abb8 e1a8651e660a c2ef9370c561 005d77857de9
I0312 13:01:25.138520    5622 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0312 13:01:25.617459    5622 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0312 13:01:25.862230    5622 kubeadm.go:155] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0312 13:01:25.862342    5622 kubeadm.go:157] found existing configuration files:

I0312 13:01:25.862670    5622 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0312 13:01:26.052020    5622 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/admin.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/admin.conf: No such file or directory
I0312 13:01:26.052396    5622 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/admin.conf
I0312 13:01:26.250607    5622 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0312 13:01:26.432224    5622 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/kubelet.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/kubelet.conf: No such file or directory
I0312 13:01:26.432638    5622 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/kubelet.conf
I0312 13:01:26.627000    5622 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0312 13:01:26.818810    5622 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/controller-manager.conf: No such file or directory
I0312 13:01:26.819197    5622 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0312 13:01:27.022009    5622 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0312 13:01:27.213091    5622 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/scheduler.conf: No such file or directory
I0312 13:01:27.213543    5622 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0312 13:01:27.421863    5622 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0312 13:01:27.647491    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0312 13:01:29.767575    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": (2.119962812s)
I0312 13:01:29.767684    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0312 13:01:54.069460    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (24.301048995s)
I0312 13:01:54.069817    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0312 13:01:58.942896    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml": (4.872943251s)
I0312 13:01:58.942993    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0312 13:02:00.175185    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml": (1.232065037s)
I0312 13:02:00.175651    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0312 13:02:01.744144    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml": (1.568393658s)
I0312 13:02:01.744288    5622 api_server.go:52] waiting for apiserver process to appear ...
I0312 13:02:01.744656    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:02.429504    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:03.196717    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:03.865462    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:04.519771    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:05.254349    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:05.964770    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:06.464651    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:10.275596    5622 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (3.809837592s)
I0312 13:02:10.277237    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:10.947175    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:11.254056    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:11.745027    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:12.245025    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:12.746545    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:13.545347    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:14.256302    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:14.745579    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:15.410104    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:15.776697    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:16.245056    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:16.867210    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:17.610967    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:18.262940    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:18.805987    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:19.946236    5622 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (1.140124229s)
I0312 13:02:19.946756    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:20.754178    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:23.159686    5622 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (2.405354583s)
I0312 13:02:23.160110    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:23.593973    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:24.042464    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:24.417138    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:25.095530    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:25.726752    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:26.215131    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:27.039564    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:27.892019    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:28.449224    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:28.993788    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:29.355955    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:29.943026    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:02:30.704143    5622 api_server.go:72] duration metric: took 28.959868028s to wait for apiserver process to appear ...
I0312 13:02:30.704215    5622 api_server.go:88] waiting for apiserver healthz status ...
I0312 13:02:30.704354    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:30.712791    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:31.205472    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:31.213631    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:31.706394    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:31.711747    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:32.205076    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:32.211771    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:32.704780    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:32.708010    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:33.205240    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:33.210393    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:33.705357    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:33.709007    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:34.205477    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:34.210767    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:34.705050    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:34.712202    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:35.206741    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:35.220692    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:35.705687    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:35.711102    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:36.207614    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:36.219655    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:36.707432    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:36.711770    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:37.204601    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:37.213205    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:37.706044    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:37.713677    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:38.205440    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:38.216167    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:38.705490    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:38.709020    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:39.205164    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:39.212697    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": dial tcp 192.168.59.100:8443: connect: connection refused
I0312 13:02:39.705333    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:44.707558    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:02:44.707706    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:49.709479    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:02:49.709605    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:54.716621    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:02:54.716786    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:02:59.720100    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:02:59.720227    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:04.721340    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:04.721473    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:09.723446    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:09.723574    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:14.724742    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:14.724872    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:19.726031    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:19.726158    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:24.732532    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:24.732664    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:29.734121    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:29.734290    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:03:34.739466    5622 api_server.go:269] stopped: https://192.168.59.100:8443/healthz: Get "https://192.168.59.100:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0312 13:03:34.740024    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0312 13:03:35.303177    5622 logs.go:282] 2 containers: [9608b9305184 c68df857a62e]
I0312 13:03:35.303650    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0312 13:03:35.768063    5622 logs.go:282] 2 containers: [9f7335fb986b b4dc10883aec]
I0312 13:03:35.768509    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0312 13:03:36.122888    5622 logs.go:282] 1 containers: [716ead16b19e]
I0312 13:03:36.123323    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0312 13:03:36.775809    5622 logs.go:282] 2 containers: [4558fe70422c b5f6cb45bea2]
I0312 13:03:36.776216    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0312 13:03:37.207630    5622 logs.go:282] 1 containers: [382239b31e68]
I0312 13:03:37.208020    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0312 13:03:37.647666    5622 logs.go:282] 2 containers: [5ea32f339a34 0b9ee0c29ff2]
I0312 13:03:37.648084    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0312 13:03:38.049119    5622 logs.go:282] 0 containers: []
W0312 13:03:38.049203    5622 logs.go:284] No container was found matching "kindnet"
I0312 13:03:38.049589    5622 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0312 13:03:38.461919    5622 logs.go:282] 1 containers: [a6516a9206ef]
I0312 13:03:38.462046    5622 logs.go:123] Gathering logs for kube-scheduler [4558fe70422c] ...
I0312 13:03:38.462102    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4558fe70422c"
I0312 13:03:38.984401    5622 logs.go:123] Gathering logs for kube-proxy [382239b31e68] ...
I0312 13:03:38.984476    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 382239b31e68"
I0312 13:03:39.916341    5622 logs.go:123] Gathering logs for describe nodes ...
I0312 13:03:39.916425    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.32.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0312 13:04:02.895974    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.32.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": (22.979439061s)
I0312 13:04:02.931753    5622 logs.go:123] Gathering logs for coredns [716ead16b19e] ...
I0312 13:04:02.931841    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 716ead16b19e"
I0312 13:04:04.588161    5622 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 716ead16b19e": (1.656200438s)
I0312 13:04:04.854031    5622 logs.go:123] Gathering logs for etcd [9f7335fb986b] ...
I0312 13:04:04.854110    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9f7335fb986b"
I0312 13:04:05.955027    5622 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 9f7335fb986b": (1.100819114s)
I0312 13:04:06.065803    5622 logs.go:123] Gathering logs for dmesg ...
I0312 13:04:06.065888    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0312 13:04:06.931934    5622 logs.go:123] Gathering logs for kube-apiserver [c68df857a62e] ...
I0312 13:04:06.932017    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c68df857a62e"
I0312 13:04:07.640979    5622 logs.go:123] Gathering logs for kube-controller-manager [0b9ee0c29ff2] ...
I0312 13:04:07.641075    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0b9ee0c29ff2"
W0312 13:04:08.206796    5622 logs.go:130] failed kube-controller-manager [0b9ee0c29ff2]: command: /bin/bash -c "docker logs --tail 400 0b9ee0c29ff2" /bin/bash -c "docker logs --tail 400 0b9ee0c29ff2": Process exited with status 1
stdout:

stderr:
Error response from daemon: No such container: 0b9ee0c29ff2
 output: 
** stderr ** 
Error response from daemon: No such container: 0b9ee0c29ff2

** /stderr **
I0312 13:04:08.206852    5622 logs.go:123] Gathering logs for storage-provisioner [a6516a9206ef] ...
I0312 13:04:08.206937    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a6516a9206ef"
I0312 13:04:09.475135    5622 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 a6516a9206ef": (1.268078409s)
I0312 13:04:09.477008    5622 logs.go:123] Gathering logs for Docker ...
I0312 13:04:09.477081    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0312 13:04:10.719795    5622 logs.go:123] Gathering logs for kubelet ...
I0312 13:04:10.719902    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0312 13:04:12.203515    5622 logs.go:123] Gathering logs for kube-apiserver [9608b9305184] ...
I0312 13:04:12.203601    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9608b9305184"
I0312 13:04:12.885972    5622 logs.go:123] Gathering logs for kube-controller-manager [5ea32f339a34] ...
I0312 13:04:12.886068    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5ea32f339a34"
I0312 13:04:13.495146    5622 logs.go:123] Gathering logs for container status ...
I0312 13:04:13.495232    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0312 13:04:15.790777    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a": (2.295425453s)
I0312 13:04:15.803428    5622 logs.go:123] Gathering logs for etcd [b4dc10883aec] ...
I0312 13:04:15.803514    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b4dc10883aec"
I0312 13:04:18.403657    5622 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 b4dc10883aec": (2.600044582s)
I0312 13:04:19.402847    5622 logs.go:123] Gathering logs for kube-scheduler [b5f6cb45bea2] ...
I0312 13:04:19.402968    5622 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5f6cb45bea2"
I0312 13:04:20.997663    5622 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 b5f6cb45bea2": (1.594503832s)
I0312 13:04:24.409673    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:04:25.448022    5622 api_server.go:279] https://192.168.59.100:8443/healthz returned 200:
ok
I0312 13:04:26.580152    5622 api_server.go:141] control plane version: v1.32.0
I0312 13:04:26.580238    5622 api_server.go:131] duration metric: took 1m55.875983074s to wait for apiserver health ...
I0312 13:04:26.580320    5622 cni.go:84] Creating CNI manager for ""
I0312 13:04:26.580396    5622 cni.go:158] "virtualbox" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0312 13:04:26.594108    5622 out.go:177] üîó  Configuring bridge CNI (Container Networking Interface) ...
I0312 13:04:26.610906    5622 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0312 13:04:28.114850    5622 ssh_runner.go:235] Completed: sudo mkdir -p /etc/cni/net.d: (1.503831732s)
I0312 13:04:28.114998    5622 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (496 bytes)
I0312 13:04:29.328090    5622 system_pods.go:43] waiting for kube-system pods to appear ...
I0312 13:04:30.629403    5622 system_pods.go:59] 7 kube-system pods found
I0312 13:04:30.629514    5622 system_pods.go:61] "coredns-668d6bf9bc-k7dr9" [876ea84d-2dc9-4850-b3f3-61b96e4ad0f8] Running
I0312 13:04:30.629570    5622 system_pods.go:61] "etcd-minikube" [cc35abc5-6fdf-4620-839e-6d729176c58e] Running
I0312 13:04:30.629642    5622 system_pods.go:61] "kube-apiserver-minikube" [5077b81c-a461-4e3d-9411-38a33fadb152] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0312 13:04:30.629686    5622 system_pods.go:61] "kube-controller-manager-minikube" [9a8aebb6-ef69-4e98-a944-3d68664fa67e] Running
I0312 13:04:30.629728    5622 system_pods.go:61] "kube-proxy-bz7pp" [ea695cc8-77d3-4f11-8e87-d01a4c49f954] Running
I0312 13:04:30.629757    5622 system_pods.go:61] "kube-scheduler-minikube" [d1a606eb-5082-409e-8412-fc30643274fa] Running
I0312 13:04:30.629787    5622 system_pods.go:61] "storage-provisioner" [81faf0e6-dde1-4796-9afd-cc12dfa229c0] Running
I0312 13:04:30.629826    5622 system_pods.go:74] duration metric: took 1.301684895s to wait for pod list to return data ...
I0312 13:04:30.629869    5622 node_conditions.go:102] verifying NodePressure condition ...
I0312 13:04:31.143391    5622 node_conditions.go:122] node storage ephemeral capacity is 17734596Ki
I0312 13:04:31.143526    5622 node_conditions.go:123] node cpu capacity is 2
I0312 13:04:31.143590    5622 node_conditions.go:105] duration metric: took 513.689756ms to run NodePressure ...
I0312 13:04:31.143765    5622 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0312 13:04:38.790002    5622 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.32.0:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml": (7.646143128s)
I0312 13:04:38.790107    5622 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0312 13:04:38.971688    5622 ops.go:34] apiserver oom_adj: -16
I0312 13:04:38.971743    5622 kubeadm.go:597] duration metric: took 3m15.514282498s to restartPrimaryControlPlane
I0312 13:04:38.971798    5622 kubeadm.go:394] duration metric: took 3m16.152106312s to StartCluster
I0312 13:04:38.971890    5622 settings.go:142] acquiring lock: {Name:mkf7c34ec77960be588296a284d7973cac6a6e6a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0312 13:04:38.973901    5622 settings.go:150] Updating kubeconfig:  /home/mohammed/.kube/config
I0312 13:04:38.986755    5622 lock.go:35] WriteFile acquiring /home/mohammed/.kube/config: {Name:mk9d402687d14a6aedf1b63aa61747599cc12026 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0312 13:04:38.992987    5622 config.go:182] Loaded profile config "minikube": Driver=virtualbox, ContainerRuntime=docker, KubernetesVersion=v1.32.0
I0312 13:04:38.993969    5622 addons.go:511] enable addons start: toEnable=map[ambassador:false amd-gpu-device-plugin:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volcano:false volumesnapshots:false yakd:false]
I0312 13:04:38.994678    5622 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0312 13:04:38.994731    5622 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0312 13:04:38.994771    5622 addons.go:238] Setting addon storage-provisioner=true in "minikube"
I0312 13:04:38.994814    5622 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
W0312 13:04:38.994823    5622 addons.go:247] addon storage-provisioner should already be in state true
I0312 13:04:38.995032    5622 host.go:66] Checking if "minikube" exists ...
I0312 13:04:38.996473    5622 global.go:112] Querying for installed drivers using PATH=/home/mohammed/.minikube/bin:/home/mohammed/.local/bin:/home/mohammed/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/home/mohammed/.local/share/JetBrains/Toolbox/scripts
I0312 13:04:38.996631    5622 global.go:133] ssh default: false priority: 4, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0312 13:04:38.997025    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 13:04:38.997835    5622 global.go:133] kvm2 default: true priority: 8, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "virsh": executable file not found in $PATH Reason: Fix:Install libvirt Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/kvm2/ Version:}
I0312 13:04:39.001488    5622 global.go:133] qemu2 default: true priority: 7, state: {Installed:true Healthy:true Running:true NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0312 13:04:39.007242    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 13:04:39.532932    5622 virtualbox.go:136] virtual box version: 7.0.18_Ubuntur162988
I0312 13:04:39.533616    5622 global.go:133] virtualbox default: true priority: 6, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:7.0.18_Ubuntur162988
}
I0312 13:04:39.536786    5622 global.go:133] vmware default: false priority: 5, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "vmrun": executable file not found in $PATH Reason: Fix:Install vmrun Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/ Version:}
I0312 13:04:39.593372    5622 out.go:201] [31m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m    You have selected "virtualbox" driver, but there are better options !                          [31m‚îÇ[0m
[31m‚îÇ[0m    For better performance and support consider using a different driver:                          [31m‚îÇ[0m
[31m‚îÇ[0m            - qemu2                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m    To turn off this warning run:                                                                  [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m            $ minikube config set WantVirtualBoxDriverWarning false                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m    To learn more about on minikube drivers checkout https://minikube.sigs.k8s.io/docs/drivers/    [31m‚îÇ[0m
[31m‚îÇ[0m    To see benchmarks checkout https://minikube.sigs.k8s.io/docs/benchmarks/cpuusage/              [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                   [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
I0312 13:04:39.601730    5622 start.go:235] Will wait 6m0s for node &{Name: IP:192.168.59.100 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I0312 13:04:39.605398    5622 out.go:177] üîé  Verifying Kubernetes components...
I0312 13:04:39.615700    5622 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0312 13:04:40.545633    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 13:04:40.545778    5622 main.go:141] libmachine: STDERR:
{
}
I0312 13:04:40.556303    5622 addons.go:238] Setting addon default-storageclass=true in "minikube"
W0312 13:04:40.556385    5622 addons.go:247] addon default-storageclass should already be in state true
I0312 13:04:40.556547    5622 host.go:66] Checking if "minikube" exists ...
I0312 13:04:40.562813    5622 main.go:141] libmachine: COMMAND: /usr/bin/VBoxManage showvminfo minikube --machinereadable
I0312 13:04:40.850574    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 13:04:40.850754    5622 main.go:141] libmachine: STDERR:
{
}
I0312 13:04:40.867793    5622 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0312 13:04:40.873840    5622 addons.go:435] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0312 13:04:40.873908    5622 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0312 13:04:40.873992    5622 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:39961 SSHKeyPath:/home/mohammed/.minikube/machines/minikube/id_rsa Username:docker}
I0312 13:04:41.906874    5622 main.go:141] libmachine: STDOUT:
{
name="minikube"
encryption="disabled"
groups="/"
ostype="Linux 2.6 / 3.x / 4.x / 5.x (64-bit)"
UUID="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
CfgFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.vbox"
SnapFldr="/home/mohammed/.minikube/machines/minikube/minikube/Snapshots"
LogFldr="/home/mohammed/.minikube/machines/minikube/minikube/Logs"
hardwareuuid="fdcbcf51-0cbd-4f1e-9ca6-e09c797a9657"
memory=2200
pagefusion="off"
vram=8
cpuexecutioncap=100
hpet="on"
cpu-profile="host"
chipset="piix3"
firmware="BIOS"
cpus=2
pae="on"
longmode="on"
triplefaultreset="off"
apic="on"
x2apic="off"
nested-hw-virt="off"
cpuid-portability-level=0
bootmenu="disabled"
boot1="dvd"
boot2="dvd"
boot3="disk"
boot4="none"
acpi="on"
ioapic="on"
biosapic="apic"
biossystemtimeoffset=0
NvramFile="/home/mohammed/.minikube/machines/minikube/minikube/minikube.nvram"
rtcuseutc="on"
hwvirtex="on"
nestedpaging="on"
largepages="on"
vtxvpid="on"
vtxux="on"
virtvmsavevmload="on"
iommu="none"
paravirtprovider="default"
effparavirtprovider="kvm"
VMState="running"
VMStateChangeTime="2025-03-12T11:57:08.813000000"
graphicscontroller="vboxvga"
monitorcount=1
accelerate3d="off"
accelerate2dvideo="off"
teleporterenabled="off"
teleporterport=0
teleporteraddress=""
teleporterpassword=""
tracing-enabled="off"
tracing-allow-vm-access="off"
tracing-config=""
autostart-enabled="off"
autostart-delay=0
defaultfrontend=""
vmprocpriority="default"
storagecontrollername0="SATA"
storagecontrollertype0="IntelAhci"
storagecontrollerinstance0="0"
storagecontrollermaxportcount0="30"
storagecontrollerportcount0="30"
storagecontrollerbootable0="on"
"SATA-0-0"="/home/mohammed/.minikube/machines/minikube/boot2docker.iso"
"SATA-ImageUUID-0-0"="d91c3a08-e42d-4149-9b31-654b97f44874"
"SATA-tempeject-0-0"="off"
"SATA-IsEjected-0-0"="off"
"SATA-hot-pluggable-0-0"="off"
"SATA-nonrotational-0-0"="off"
"SATA-discard-0-0"="off"
"SATA-1-0"="/home/mohammed/.minikube/machines/minikube/disk.vmdk"
"SATA-ImageUUID-1-0"="45330852-8dbb-435a-8bca-16028d742f81"
"SATA-hot-pluggable-1-0"="off"
"SATA-nonrotational-1-0"="off"
"SATA-discard-1-0"="off"
"SATA-2-0"="none"
"SATA-3-0"="none"
"SATA-4-0"="none"
"SATA-5-0"="none"
"SATA-6-0"="none"
"SATA-7-0"="none"
"SATA-8-0"="none"
"SATA-9-0"="none"
"SATA-10-0"="none"
"SATA-11-0"="none"
"SATA-12-0"="none"
"SATA-13-0"="none"
"SATA-14-0"="none"
"SATA-15-0"="none"
"SATA-16-0"="none"
"SATA-17-0"="none"
"SATA-18-0"="none"
"SATA-19-0"="none"
"SATA-20-0"="none"
"SATA-21-0"="none"
"SATA-22-0"="none"
"SATA-23-0"="none"
"SATA-24-0"="none"
"SATA-25-0"="none"
"SATA-26-0"="none"
"SATA-27-0"="none"
"SATA-28-0"="none"
"SATA-29-0"="none"
natnet1="nat"
macaddress1="080027F5CA92"
cableconnected1="on"
nic1="nat"
nictype1="virtio"
nicspeed1="0"
mtu="0"
sockSnd="64"
sockRcv="64"
tcpWndSnd="64"
tcpWndRcv="64"
Forwarding(0)="ssh,tcp,127.0.0.1,39961,,22"
hostonlyadapter2="vboxnet0"
macaddress2="080027210068"
cableconnected2="on"
nic2="hostonly"
nictype2="virtio"
nicspeed2="0"
nic3="none"
nic4="none"
nic5="none"
nic6="none"
nic7="none"
nic8="none"
hidpointing="ps2mouse"
hidkeyboard="ps2kbd"
uart1="off"
uart2="off"
uart3="off"
uart4="off"
lpt1="off"
lpt2="off"
audio="default"
audio_out="off"
audio_in="off"
clipboard="disabled"
draganddrop="disabled"
SessionName="headless"
VideoMode="720,400,0"@0,0 1
vrde="off"
usb="off"
ehci="off"
xhci="off"
SharedFolderNameMachineMapping1="hosthome"
SharedFolderPathMachineMapping1="/home"
VRDEActiveConnection="off"
VRDEClients==0
recording_enabled="off"
recording_screens=1
 rec_screen0
rec_screen_enabled="on"
rec_screen_id=0
rec_screen_video_enabled="on"
rec_screen_dest="File"
rec_screen_dest_filename="/home/mohammed/.minikube/machines/minikube/minikube/minikube-screen0.webm"
rec_screen_opts="vc_enabled=true,ac_enabled=false,ac_profile=med"
rec_screen_video_res_xy="1024x768"
rec_screen_video_rate_kbps=512
rec_screen_video_fps=25
GuestMemoryBalloon=0
GuestOSType="Linux26_64"
GuestAdditionsRunLevel=2
GuestAdditionsVersion="6.0.0 r127566"
GuestAdditionsFacility_VirtualBox Base Driver=50,1741780755389
GuestAdditionsFacility_VirtualBox System Service=50,1741780760872
GuestAdditionsFacility_Seamless Mode=0,1741780755351
GuestAdditionsFacility_Graphics Mode=0,1741780755350
}
I0312 13:04:41.907017    5622 main.go:141] libmachine: STDERR:
{
}
I0312 13:04:41.908130    5622 addons.go:435] installing /etc/kubernetes/addons/storageclass.yaml
I0312 13:04:41.908186    5622 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0312 13:04:41.908313    5622 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:39961 SSHKeyPath:/home/mohammed/.minikube/machines/minikube/id_rsa Username:docker}
I0312 13:04:47.179974    5622 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (7.564149934s)
I0312 13:04:47.180392    5622 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0312 13:04:47.648991    5622 api_server.go:52] waiting for apiserver process to appear ...
I0312 13:04:47.649425    5622 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0312 13:04:48.291820    5622 api_server.go:72] duration metric: took 8.689903043s to wait for apiserver process to appear ...
I0312 13:04:48.291892    5622 api_server.go:88] waiting for apiserver healthz status ...
I0312 13:04:48.292045    5622 api_server.go:253] Checking apiserver healthz at https://192.168.59.100:8443/healthz ...
I0312 13:04:48.613008    5622 api_server.go:279] https://192.168.59.100:8443/healthz returned 200:
ok
I0312 13:04:48.620994    5622 api_server.go:141] control plane version: v1.32.0
I0312 13:04:48.621071    5622 api_server.go:131] duration metric: took 329.138774ms to wait for apiserver health ...
I0312 13:04:48.621118    5622 system_pods.go:43] waiting for kube-system pods to appear ...
I0312 13:04:48.834658    5622 system_pods.go:59] 7 kube-system pods found
I0312 13:04:48.834776    5622 system_pods.go:61] "coredns-668d6bf9bc-k7dr9" [876ea84d-2dc9-4850-b3f3-61b96e4ad0f8] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0312 13:04:48.834913    5622 system_pods.go:61] "etcd-minikube" [cc35abc5-6fdf-4620-839e-6d729176c58e] Running
I0312 13:04:48.834969    5622 system_pods.go:61] "kube-apiserver-minikube" [5077b81c-a461-4e3d-9411-38a33fadb152] Running
I0312 13:04:48.835027    5622 system_pods.go:61] "kube-controller-manager-minikube" [9a8aebb6-ef69-4e98-a944-3d68664fa67e] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0312 13:04:48.835081    5622 system_pods.go:61] "kube-proxy-bz7pp" [ea695cc8-77d3-4f11-8e87-d01a4c49f954] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0312 13:04:48.835119    5622 system_pods.go:61] "kube-scheduler-minikube" [d1a606eb-5082-409e-8412-fc30643274fa] Running
I0312 13:04:48.835173    5622 system_pods.go:61] "storage-provisioner" [81faf0e6-dde1-4796-9afd-cc12dfa229c0] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0312 13:04:48.835284    5622 system_pods.go:74] duration metric: took 214.088001ms to wait for pod list to return data ...
I0312 13:04:48.835368    5622 kubeadm.go:582] duration metric: took 9.233447499s to wait for: map[apiserver:true system_pods:true]
I0312 13:04:48.835446    5622 node_conditions.go:102] verifying NodePressure condition ...
I0312 13:04:48.915911    5622 node_conditions.go:122] node storage ephemeral capacity is 17734596Ki
I0312 13:04:48.915986    5622 node_conditions.go:123] node cpu capacity is 2
I0312 13:04:48.916038    5622 node_conditions.go:105] duration metric: took 80.560469ms to run NodePressure ...
I0312 13:04:48.916136    5622 start.go:241] waiting for startup goroutines ...
I0312 13:04:50.832410    5622 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0312 13:04:52.366546    5622 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0312 13:05:32.227551    5622 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (39.860845526s)
I0312 13:05:32.229392    5622 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (41.39679004s)
I0312 13:05:32.394770    5622 out.go:177] üåü  Enabled addons: storage-provisioner, default-storageclass
I0312 13:05:32.399589    5622 addons.go:514] duration metric: took 53.405606727s for enable addons: enabled=[storage-provisioner default-storageclass]
I0312 13:05:32.399868    5622 start.go:246] waiting for cluster config update ...
I0312 13:05:32.399982    5622 start.go:255] writing updated cluster config ...
I0312 13:05:32.403964    5622 ssh_runner.go:195] Run: rm -f paused
I0312 13:05:33.746798    5622 start.go:600] kubectl: 1.32.1, cluster: 1.32.0 (minor skew: 0)
I0312 13:05:33.751237    5622 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default


==> Docker <==
Mar 12 13:21:56 minikube cri-dockerd[1284]: time="2025-03-12T13:21:56Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==>                                                ]  10.03MB/191.9MB"
Mar 12 13:22:00 minikube dockerd[1019]: time="2025-03-12T13:22:00.282172430Z" level=info msg="shim disconnected" id=205013e30d8804df6e4be41e4d213e6c2d248341ec10b0a1eb7d5383e7767885 namespace=moby
Mar 12 13:22:00 minikube dockerd[1013]: time="2025-03-12T13:22:00.317442771Z" level=info msg="ignoring event" container=205013e30d8804df6e4be41e4d213e6c2d248341ec10b0a1eb7d5383e7767885 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 12 13:22:00 minikube dockerd[1019]: time="2025-03-12T13:22:00.319720758Z" level=warning msg="cleaning up after shim disconnected" id=205013e30d8804df6e4be41e4d213e6c2d248341ec10b0a1eb7d5383e7767885 namespace=moby
Mar 12 13:22:00 minikube dockerd[1019]: time="2025-03-12T13:22:00.319982137Z" level=info msg="cleaning up dead shim" namespace=moby
Mar 12 13:22:05 minikube cri-dockerd[1284]: time="2025-03-12T13:22:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==>                                                ]  10.58MB/191.9MB"
Mar 12 13:22:08 minikube dockerd[1019]: time="2025-03-12T13:22:08.157821602Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Mar 12 13:22:08 minikube dockerd[1019]: time="2025-03-12T13:22:08.223301967Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Mar 12 13:22:08 minikube dockerd[1019]: time="2025-03-12T13:22:08.232685119Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Mar 12 13:22:08 minikube dockerd[1019]: time="2025-03-12T13:22:08.284825061Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Mar 12 13:22:15 minikube cri-dockerd[1284]: time="2025-03-12T13:22:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==>                                                ]  11.14MB/191.9MB"
Mar 12 13:22:25 minikube cri-dockerd[1284]: time="2025-03-12T13:22:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [===>                                               ]  12.81MB/191.9MB"
Mar 12 13:22:35 minikube cri-dockerd[1284]: time="2025-03-12T13:22:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [===>                                               ]  14.48MB/191.9MB"
Mar 12 13:22:45 minikube cri-dockerd[1284]: time="2025-03-12T13:22:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [====>                                              ]  16.15MB/191.9MB"
Mar 12 13:22:55 minikube cri-dockerd[1284]: time="2025-03-12T13:22:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [====>                                              ]  18.38MB/191.9MB"
Mar 12 13:23:05 minikube cri-dockerd[1284]: time="2025-03-12T13:23:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [======>                                            ]   23.4MB/191.9MB"
Mar 12 13:23:15 minikube cri-dockerd[1284]: time="2025-03-12T13:23:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [=======>                                           ]  28.41MB/191.9MB"
Mar 12 13:23:25 minikube cri-dockerd[1284]: time="2025-03-12T13:23:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [=========>                                         ]  35.09MB/191.9MB"
Mar 12 13:23:35 minikube cri-dockerd[1284]: time="2025-03-12T13:23:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==========>                                        ]  41.22MB/191.9MB"
Mar 12 13:23:45 minikube cri-dockerd[1284]: time="2025-03-12T13:23:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [============>                                      ]  48.46MB/191.9MB"
Mar 12 13:23:55 minikube cri-dockerd[1284]: time="2025-03-12T13:23:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==============>                                    ]  56.82MB/191.9MB"
Mar 12 13:24:05 minikube cri-dockerd[1284]: time="2025-03-12T13:24:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [===============>                                   ]  61.28MB/191.9MB"
Mar 12 13:24:15 minikube cri-dockerd[1284]: time="2025-03-12T13:24:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [================>                                  ]  65.18MB/191.9MB"
Mar 12 13:24:25 minikube cri-dockerd[1284]: time="2025-03-12T13:24:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==================>                                ]   71.3MB/191.9MB"
Mar 12 13:24:35 minikube cri-dockerd[1284]: time="2025-03-12T13:24:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [====================>                              ]  77.99MB/191.9MB"
Mar 12 13:24:45 minikube cri-dockerd[1284]: time="2025-03-12T13:24:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [======================>                            ]   86.9MB/191.9MB"
Mar 12 13:24:55 minikube cri-dockerd[1284]: time="2025-03-12T13:24:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [========================>                          ]  93.03MB/191.9MB"
Mar 12 13:25:05 minikube cri-dockerd[1284]: time="2025-03-12T13:25:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==========================>                        ]  101.9MB/191.9MB"
Mar 12 13:25:15 minikube cri-dockerd[1284]: time="2025-03-12T13:25:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [============================>                      ]  110.9MB/191.9MB"
Mar 12 13:25:25 minikube cri-dockerd[1284]: time="2025-03-12T13:25:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==============================>                    ]  118.7MB/191.9MB"
Mar 12 13:25:36 minikube cri-dockerd[1284]: time="2025-03-12T13:25:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [================================>                  ]  126.5MB/191.9MB"
Mar 12 13:25:45 minikube cri-dockerd[1284]: time="2025-03-12T13:25:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==================================>                ]  133.7MB/191.9MB"
Mar 12 13:25:55 minikube cri-dockerd[1284]: time="2025-03-12T13:25:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [====================================>              ]  140.4MB/191.9MB"
Mar 12 13:26:05 minikube cri-dockerd[1284]: time="2025-03-12T13:26:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [======================================>            ]  147.6MB/191.9MB"
Mar 12 13:26:15 minikube cri-dockerd[1284]: time="2025-03-12T13:26:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==========================================>        ]  164.9MB/191.9MB"
Mar 12 13:26:25 minikube cri-dockerd[1284]: time="2025-03-12T13:26:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [=============================================>     ]  174.9MB/191.9MB"
Mar 12 13:26:35 minikube cri-dockerd[1284]: time="2025-03-12T13:26:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==============================================>    ]  179.9MB/191.9MB"
Mar 12 13:26:45 minikube cri-dockerd[1284]: time="2025-03-12T13:26:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [================================================>  ]  185.5MB/191.9MB"
Mar 12 13:26:55 minikube cri-dockerd[1284]: time="2025-03-12T13:26:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [=================================================> ]  188.8MB/191.9MB"
Mar 12 13:27:05 minikube cri-dockerd[1284]: time="2025-03-12T13:27:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [=================================================> ]  190.5MB/191.9MB"
Mar 12 13:27:15 minikube cri-dockerd[1284]: time="2025-03-12T13:27:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 513d77925604: Extracting [==================================================>]  191.9MB/191.9MB"
Mar 12 13:27:25 minikube cri-dockerd[1284]: time="2025-03-12T13:27:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 0e421f66aff4: Extracting [=========>                                         ]  6.488MB/34.79MB"
Mar 12 13:27:35 minikube cri-dockerd[1284]: time="2025-03-12T13:27:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 0e421f66aff4: Extracting [====================>                              ]  14.42MB/34.79MB"
Mar 12 13:27:45 minikube cri-dockerd[1284]: time="2025-03-12T13:27:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 0e421f66aff4: Extracting [=================================>                 ]  23.07MB/34.79MB"
Mar 12 13:27:55 minikube cri-dockerd[1284]: time="2025-03-12T13:27:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 0e421f66aff4: Extracting [=========================================>         ]   29.2MB/34.79MB"
Mar 12 13:28:05 minikube cri-dockerd[1284]: time="2025-03-12T13:28:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 0e421f66aff4: Extracting [==============================================>    ]  32.44MB/34.79MB"
Mar 12 13:28:15 minikube cri-dockerd[1284]: time="2025-03-12T13:28:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: 0e421f66aff4: Extracting [================================================>  ]  33.52MB/34.79MB"
Mar 12 13:28:25 minikube cri-dockerd[1284]: time="2025-03-12T13:28:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: ca266fd61921: Extracting [=========================>                         ]   1.18MB/2.273MB"
Mar 12 13:28:35 minikube cri-dockerd[1284]: time="2025-03-12T13:28:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: aa42a010293f: Extracting [=============================>                     ]  5.308MB/9.094MB"
Mar 12 13:28:45 minikube cri-dockerd[1284]: time="2025-03-12T13:28:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: aa42a010293f: Extracting [================================>                  ]  5.997MB/9.094MB"
Mar 12 13:28:55 minikube cri-dockerd[1284]: time="2025-03-12T13:28:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: aa42a010293f: Extracting [==================================>                ]  6.193MB/9.094MB"
Mar 12 13:29:05 minikube cri-dockerd[1284]: time="2025-03-12T13:29:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: aa42a010293f: Extracting [=====================================>             ]  6.881MB/9.094MB"
Mar 12 13:29:15 minikube cri-dockerd[1284]: time="2025-03-12T13:29:15Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: aa42a010293f: Extracting [===============================================>   ]  8.651MB/9.094MB"
Mar 12 13:29:25 minikube cri-dockerd[1284]: time="2025-03-12T13:29:25Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: cbdc784ea15d: Extracting [==============>                                    ]  1.245MB/4.384MB"
Mar 12 13:29:35 minikube cri-dockerd[1284]: time="2025-03-12T13:29:35Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: cbdc784ea15d: Extracting [==============>                                    ]  1.311MB/4.384MB"
Mar 12 13:29:45 minikube cri-dockerd[1284]: time="2025-03-12T13:29:45Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: cbdc784ea15d: Extracting [=================>                                 ]  1.507MB/4.384MB"
Mar 12 13:29:55 minikube cri-dockerd[1284]: time="2025-03-12T13:29:55Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: cbdc784ea15d: Extracting [===========================>                       ]  2.425MB/4.384MB"
Mar 12 13:30:05 minikube cri-dockerd[1284]: time="2025-03-12T13:30:05Z" level=info msg="Pulling image hamamebch/rental-manager:0.1: cbdc784ea15d: Extracting [=============================================>     ]  3.998MB/4.384MB"
Mar 12 13:30:14 minikube cri-dockerd[1284]: time="2025-03-12T13:30:14Z" level=info msg="Stop pulling image hamamebch/rental-manager:0.1: Status: Downloaded newer image for hamamebch/rental-manager:0.1"
Mar 12 13:30:15 minikube dockerd[1013]: time="2025-03-12T13:30:15.325682822Z" level=warning msg="reference for unknown type: " digest="sha256:a9f03b34a3cbfbb26d103a14046ab2c5130a80c3d69d526ff8063d2b37b9fd3f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:a9f03b34a3cbfbb26d103a14046ab2c5130a80c3d69d526ff8063d2b37b9fd3f" spanID=0d512963f8ebcc4f traceID=d1790ab9390432b40e369aea0e159bdb


==> container status <==
CONTAINER           IMAGE                                                                                              CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
893bb3a07f696       hamamebch/rental-manager@sha256:3bddf561f1d7d435e91014da0ef36e52509ccf53a2dfc0bf4ecd93a51f998008   5 seconds ago       Created             serviceadmin              0                   70d48ca00856c       serviceadmin-7dc8b8788f-tcg9k
9ecc603e66307       6e38f40d628db                                                                                      8 minutes ago       Running             storage-provisioner       113                 9577e0c23b1a8       storage-provisioner
205013e30d880       6e38f40d628db                                                                                      19 minutes ago      Exited              storage-provisioner       112                 9577e0c23b1a8       storage-provisioner
30101b50ae322       c69fa2e9cbf5f                                                                                      About an hour ago   Running             coredns                   3                   5c5fec93177e4       coredns-668d6bf9bc-k7dr9
3ede003cd8bd9       040f9f8aac8cd                                                                                      About an hour ago   Running             kube-proxy                2                   2411ce6048bfb       kube-proxy-bz7pp
a071185b728c2       8cab3d2a8bd0f                                                                                      About an hour ago   Running             kube-controller-manager   6                   dae307f511070       kube-controller-manager-minikube
9f7335fb986b6       a9e7e6b294baf                                                                                      About an hour ago   Running             etcd                      4                   fbc57e685ffbf       etcd-minikube
9608b9305184e       c2e17b8d0f4a3                                                                                      About an hour ago   Running             kube-apiserver            35                  e2c53fdc4dabd       kube-apiserver-minikube
4558fe70422c5       a389e107f4ff1                                                                                      About an hour ago   Running             kube-scheduler            2                   059a2812cec6d       kube-scheduler-minikube
5ea32f339a34d       8cab3d2a8bd0f                                                                                      About an hour ago   Exited              kube-controller-manager   5                   dae307f511070       kube-controller-manager-minikube
c68df857a62ec       c2e17b8d0f4a3                                                                                      3 weeks ago         Exited              kube-apiserver            34                  7fa2976fc92f2       kube-apiserver-minikube
716ead16b19e6       c69fa2e9cbf5f                                                                                      3 weeks ago         Exited              coredns                   2                   c24acc9254679       coredns-668d6bf9bc-k7dr9
b4dc10883aec0       a9e7e6b294baf                                                                                      3 weeks ago         Exited              etcd                      3                   eee621a64e0c3       etcd-minikube
b5f6cb45bea2f       a389e107f4ff1                                                                                      3 weeks ago         Exited              kube-scheduler            1                   5e8bea03e3db6       kube-scheduler-minikube


==> coredns [30101b50ae32] <==
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 301c01e493ddcb0cfc26fbb8cda8022e1bdf00ab1ffb240ebb0dd8da07cceca60b62b46a8dadeeb56413c1a160e438f6297f439c9e3d5bc5e376245d688e49ab
CoreDNS-1.11.3
linux/amd64, go1.21.11, a6338e9
[INFO] 127.0.0.1:54074 - 12683 "HINFO IN 4612497193557513218.1641343859167182015. udp 57 false 512" NOERROR qr,rd,ra 57 0.04900095s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[1375498862]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (12-Mar-2025 12:05:45.183) (total time: 30050ms):
Trace[1375498862]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30049ms (12:06:15.232)
Trace[1375498862]: [30.050832869s] [30.050832869s] END
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[946556779]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (12-Mar-2025 12:05:45.198) (total time: 30169ms):
Trace[946556779]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30167ms (12:06:15.366)
Trace[946556779]: [30.169847216s] [30.169847216s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[1546066198]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (12-Mar-2025 12:05:45.161) (total time: 30211ms):
Trace[1546066198]: ---"Objects listed" error:Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30211ms (12:06:15.373)
Trace[1546066198]: [30.211960621s] [30.211960621s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/ready: Still waiting on: "kubernetes"
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.321017244s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.137587008s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.07600032s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.027523616s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.110491793s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.351117593s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.165180993s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.518282912s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.563407599s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.928841358s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.046576266s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.580350562s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.383304006s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.710703253s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.496904596s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.836736196s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.45658483s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.24512745s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.169611521s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.126421s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.593637751s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.354954761s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.02392613s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.859221345s


==> coredns [716ead16b19e] <==
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.975375339s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.221565602s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.518216407s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.362490213s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.011803194s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.224560602s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.259819813s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.261079084s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.536169539s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.001688211s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.66488795s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.020693425s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.164539418s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.006112283s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.187455944s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.058204251s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.373938899s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.670952581s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.050003942s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.025673922s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.205468037s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.154831013s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.207928591s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.603131526s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.130025272s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.10134336s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.950611538s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.330632851s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.097486732s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.239247979s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.119199055s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.277885184s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.053358421s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.106409888s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.488614755s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.379915966s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.06846458s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.186782093s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.356981263s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.096263283s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.114622254s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.180377384s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.174095763s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.326577039s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.182998685s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.14695774s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.365466671s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.435121274s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.201465225s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.058165619s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.01647156s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.012320319s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.11077388s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.287361881s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.141501801s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.335031762s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.253426664s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.02023748s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.281478579s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.454799207s


==> describe nodes <==
Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=dd5d320e41b5451cdf3c01891bc4e13d189586ed-dirty
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2025_01_24T11_38_55_0700
                    minikube.k8s.io/version=v1.35.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Fri, 24 Jan 2025 10:37:35 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 12 Mar 2025 13:30:19 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 12 Mar 2025 13:27:06 +0000   Sat, 15 Feb 2025 14:52:53 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 12 Mar 2025 13:27:06 +0000   Sat, 15 Feb 2025 14:52:53 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 12 Mar 2025 13:27:06 +0000   Sat, 15 Feb 2025 14:52:53 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 12 Mar 2025 13:27:06 +0000   Wed, 12 Mar 2025 12:04:44 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.59.100
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17734596Ki
  hugepages-2Mi:      0
  memory:             2164268Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17734596Ki
  hugepages-2Mi:      0
  memory:             2164268Ki
  pods:               110
System Info:
  Machine ID:                 9efcd417f63d410993d0b0f71366df75
  System UUID:                51cfcbfd-bd0c-1e4f-9ca6-e09c797a9657
  Boot ID:                    d49aaf3c-8fd4-4c15-98d6-69d0f197b359
  Kernel Version:             5.10.207
  OS Image:                   Buildroot 2023.02.9
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://27.4.0
  Kubelet Version:            v1.32.0
  Kube-Proxy Version:         v1.32.0
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (11 in total)
  Namespace                   Name                                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                         ------------  ----------  ---------------  -------------  ---
  default                     serviceadmin-7dc8b8788f-tcg9k                0 (0%)        0 (0%)      0 (0%)           0 (0%)         21m
  ingress-nginx               ingress-nginx-admission-create-p8dfb         0 (0%)        0 (0%)      0 (0%)           0 (0%)         17m
  ingress-nginx               ingress-nginx-admission-patch-wt4lf          0 (0%)        0 (0%)      0 (0%)           0 (0%)         17m
  ingress-nginx               ingress-nginx-controller-56d7c84fd4-c92rw    100m (5%)     0 (0%)      90Mi (4%)        0 (0%)         17m
  kube-system                 coredns-668d6bf9bc-k7dr9                     100m (5%)     0 (0%)      70Mi (3%)        170Mi (8%)     47d
  kube-system                 etcd-minikube                                100m (5%)     0 (0%)      100Mi (4%)       0 (0%)         47d
  kube-system                 kube-apiserver-minikube                      250m (12%)    0 (0%)      0 (0%)           0 (0%)         47d
  kube-system                 kube-controller-manager-minikube             200m (10%)    0 (0%)      0 (0%)           0 (0%)         47d
  kube-system                 kube-proxy-bz7pp                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         47d
  kube-system                 kube-scheduler-minikube                      100m (5%)     0 (0%)      0 (0%)           0 (0%)         47d
  kube-system                 storage-provisioner                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         47d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                850m (42%)   0 (0%)
  memory             260Mi (12%)  170Mi (8%)
  ephemeral-storage  0 (0%)       0 (0%)
  hugepages-2Mi      0 (0%)       0 (0%)
Events:              <none>


==> dmesg <==
[Mar12 11:57] You have booted with nomodeset. This means your GPU drivers are DISABLED
[  +0.000013] Any video related functionality will be severely degraded, and you may not even be able to suspend the system properly
[  +0.000007] Unless you actually understand what nomodeset does, you should reboot without enabling it
[  +1.184726] RETBleed: WARNING: Spectre v2 mitigation leaves CPU vulnerable to RETBleed attacks, data leaks possible!
[  +0.769134] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge.
[  +1.300194] hrtimer: interrupt took 4497907 ns
[Mar12 11:58] platform regulatory.0: Direct firmware load for regulatory.db failed with error -2
[Mar12 11:59] systemd-fstab-generator[198]: Ignoring "noauto" option for root device
[  +9.575976] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
[  +0.000050] NFSD: unable to find recovery directory /var/lib/nfs/v4recovery
[  +0.000011] NFSD: Unable to initialize client recovery tracking! (-2)
[ +33.830747] systemd-fstab-generator[631]: Ignoring "noauto" option for root device
[  +3.728846] systemd-fstab-generator[643]: Ignoring "noauto" option for root device
[Mar12 12:00] kauditd_printk_skb: 30 callbacks suppressed
[ +14.633812] systemd-fstab-generator[943]: Ignoring "noauto" option for root device
[  +2.654377] kauditd_printk_skb: 31 callbacks suppressed
[  +4.752590] systemd-fstab-generator[979]: Ignoring "noauto" option for root device
[  +2.692005] kauditd_printk_skb: 10 callbacks suppressed
[  +1.198332] systemd-fstab-generator[991]: Ignoring "noauto" option for root device
[  +4.127739] systemd-fstab-generator[1005]: Ignoring "noauto" option for root device
[  +2.652755] kauditd_printk_skb: 30 callbacks suppressed
[  +5.150777] kauditd_printk_skb: 10 callbacks suppressed
[  +5.386009] systemd-fstab-generator[1237]: Ignoring "noauto" option for root device
[  +2.513154] kauditd_printk_skb: 30 callbacks suppressed
[  +1.228998] systemd-fstab-generator[1249]: Ignoring "noauto" option for root device
[  +4.009369] systemd-fstab-generator[1261]: Ignoring "noauto" option for root device
[  +2.460761] kauditd_printk_skb: 30 callbacks suppressed
[  +1.732933] systemd-fstab-generator[1276]: Ignoring "noauto" option for root device
[Mar12 12:01] systemd-fstab-generator[1398]: Ignoring "noauto" option for root device
[  +2.794276] kauditd_printk_skb: 30 callbacks suppressed
[ +42.291911] systemd-fstab-generator[1545]: Ignoring "noauto" option for root device
[  +2.206200] kauditd_printk_skb: 10 callbacks suppressed
[Mar12 12:02] kauditd_printk_skb: 15 callbacks suppressed
[ +21.406321] kauditd_printk_skb: 10 callbacks suppressed
[Mar12 12:04] kauditd_printk_skb: 10 callbacks suppressed
[ +39.221110] systemd-fstab-generator[2409]: Ignoring "noauto" option for root device
[Mar12 12:05] kauditd_printk_skb: 15 callbacks suppressed
[ +34.431597] kauditd_printk_skb: 6 callbacks suppressed
[  +5.142625] kauditd_printk_skb: 4 callbacks suppressed
[Mar12 12:06] kauditd_printk_skb: 8 callbacks suppressed


==> etcd [9f7335fb986b] <==
{"level":"info","ts":"2025-03-12T13:21:47.343725Z","caller":"traceutil/trace.go:171","msg":"trace[648169916] range","detail":"{range_begin:/registry/csinodes/; range_end:/registry/csinodes0; response_count:0; response_revision:29913; }","duration":"761.863609ms","start":"2025-03-12T13:21:46.581779Z","end":"2025-03-12T13:21:47.343643Z","steps":["trace[648169916] 'agreement among raft nodes before linearized reading'  (duration: 744.690905ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:47.344669Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:46.581651Z","time spent":"762.902124ms","remote":"127.0.0.1:47406","response type":"/etcdserverpb.KV/Range","request count":0,"request size":44,"response count":1,"response size":30,"request content":"key:\"/registry/csinodes/\" range_end:\"/registry/csinodes0\" count_only:true "}
{"level":"info","ts":"2025-03-12T13:21:47.427901Z","caller":"traceutil/trace.go:171","msg":"trace[853611608] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:29913; }","duration":"969.081787ms","start":"2025-03-12T13:21:46.367319Z","end":"2025-03-12T13:21:47.336401Z","steps":["trace[853611608] 'agreement among raft nodes before linearized reading'  (duration: 968.581437ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:52.431057Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"298.906552ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumeclaims/\" range_end:\"/registry/persistentvolumeclaims0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:21:52.431904Z","caller":"traceutil/trace.go:171","msg":"trace[827553871] range","detail":"{range_begin:/registry/persistentvolumeclaims/; range_end:/registry/persistentvolumeclaims0; response_count:0; response_revision:29914; }","duration":"299.96125ms","start":"2025-03-12T13:21:52.131858Z","end":"2025-03-12T13:21:52.431819Z","steps":["trace[827553871] 'agreement among raft nodes before linearized reading'  (duration: 298.914231ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:52.467777Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:52.131353Z","time spent":"336.303794ms","remote":"127.0.0.1:36036","response type":"/etcdserverpb.KV/Range","request count":0,"request size":72,"response count":0,"response size":28,"request content":"key:\"/registry/persistentvolumeclaims/\" range_end:\"/registry/persistentvolumeclaims0\" count_only:true "}
{"level":"info","ts":"2025-03-12T13:21:52.401191Z","caller":"traceutil/trace.go:171","msg":"trace[1803789345] linearizableReadLoop","detail":"{readStateIndex:40228; appliedIndex:40228; }","duration":"200.542772ms","start":"2025-03-12T13:21:52.132013Z","end":"2025-03-12T13:21:52.332555Z","steps":["trace[1803789345] 'read index received'  (duration: 200.518476ms)","trace[1803789345] 'applied index is now lower than readState.Index'  (duration: 18.858¬µs)"],"step_count":2}
{"level":"info","ts":"2025-03-12T13:21:52.348247Z","caller":"traceutil/trace.go:171","msg":"trace[1453512239] transaction","detail":"{read_only:false; response_revision:29914; number_of_response:1; }","duration":"256.231456ms","start":"2025-03-12T13:21:52.038955Z","end":"2025-03-12T13:21:52.295187Z","steps":["trace[1453512239] 'process raft request'  (duration: 158.266901ms)","trace[1453512239] 'compare'  (duration: 97.44698ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:21:52.517570Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:52.038435Z","time spent":"474.224579ms","remote":"127.0.0.1:36140","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":521,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:29909 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:472 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >"}
{"level":"warn","ts":"2025-03-12T13:21:52.515511Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"168.335515ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/\" range_end:\"/registry/services/endpoints0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-12T13:21:52.520190Z","caller":"traceutil/trace.go:171","msg":"trace[1719681394] range","detail":"{range_begin:/registry/services/endpoints/; range_end:/registry/services/endpoints0; response_count:0; response_revision:29914; }","duration":"173.247163ms","start":"2025-03-12T13:21:52.346829Z","end":"2025-03-12T13:21:52.520077Z","steps":["trace[1719681394] 'agreement among raft nodes before linearized reading'  (duration: 138.879561ms)","trace[1719681394] 'count revisions from in-memory index tree'  (duration: 29.65577ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:21:52.524931Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:52.210211Z","time spent":"310.279769ms","remote":"127.0.0.1:36038","response type":"/etcdserverpb.KV/Range","request count":0,"request size":64,"response count":7,"response size":30,"request content":"key:\"/registry/services/endpoints/\" range_end:\"/registry/services/endpoints0\" count_only:true "}
{"level":"warn","ts":"2025-03-12T13:21:52.507801Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"212.752181ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/podtemplates/\" range_end:\"/registry/podtemplates0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:21:52.530258Z","caller":"traceutil/trace.go:171","msg":"trace[268376329] range","detail":"{range_begin:/registry/podtemplates/; range_end:/registry/podtemplates0; response_count:0; response_revision:29914; }","duration":"234.579712ms","start":"2025-03-12T13:21:52.294075Z","end":"2025-03-12T13:21:52.528655Z","steps":["trace[268376329] 'agreement among raft nodes before linearized reading'  (duration: 191.012908ms)","trace[268376329] 'count revisions from in-memory index tree'  (duration: 22.093325ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:21:52.601164Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"279.114814ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/endpointslices/\" range_end:\"/registry/endpointslices0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-12T13:21:52.606652Z","caller":"traceutil/trace.go:171","msg":"trace[1620030414] range","detail":"{range_begin:/registry/endpointslices/; range_end:/registry/endpointslices0; response_count:0; response_revision:29914; }","duration":"284.735097ms","start":"2025-03-12T13:21:52.321806Z","end":"2025-03-12T13:21:52.606541Z","steps":["trace[1620030414] 'agreement among raft nodes before linearized reading'  (duration: 163.934769ms)","trace[1620030414] 'count revisions from in-memory index tree'  (duration: 87.931717ms)","trace[1620030414] 'filter and sort the key-value pairs'  (duration: 27.30161ms)"],"step_count":3}
{"level":"warn","ts":"2025-03-12T13:21:56.215642Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"495.761425ms","expected-duration":"100ms","prefix":"","request":"header:<ID:10324103616748530706 username:\"kube-apiserver-etcd-client\" auth_revision:1 > lease_grant:<ttl:15-second id:0f46958a3c9f2c11>","response":"size:40"}
{"level":"warn","ts":"2025-03-12T13:21:56.223958Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:55.689210Z","time spent":"534.723823ms","remote":"127.0.0.1:60444","response type":"/etcdserverpb.Lease/LeaseGrant","request count":-1,"request size":-1,"response count":-1,"response size":-1,"request content":""}
{"level":"warn","ts":"2025-03-12T13:21:57.485937Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"621.472102ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 serializable:true keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:21:57.496703Z","caller":"traceutil/trace.go:171","msg":"trace[1902671401] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:29914; }","duration":"622.038678ms","start":"2025-03-12T13:21:56.864257Z","end":"2025-03-12T13:21:57.486295Z","steps":["trace[1902671401] 'range keys from in-memory index tree'  (duration: 620.869958ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:57.864097Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.163245945s","expected-duration":"100ms","prefix":"","request":"header:<ID:10324103616748530707 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:29709 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:4538 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >>","response":"size:18"}
{"level":"info","ts":"2025-03-12T13:21:57.877806Z","caller":"traceutil/trace.go:171","msg":"trace[15893474] transaction","detail":"{read_only:false; response_revision:29915; number_of_response:1; }","duration":"2.18674124s","start":"2025-03-12T13:21:55.690913Z","end":"2025-03-12T13:21:57.877654Z","steps":["trace[15893474] 'process raft request'  (duration: 1.009371449s)","trace[15893474] 'compare'  (duration: 583.956662ms)","trace[15893474] 'store kv pair into bolt db' {req_type:put; key:/registry/minions/minikube; req_size:4569; } (duration: 245.105673ms)"],"step_count":3}
{"level":"warn","ts":"2025-03-12T13:21:57.896988Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:55.644287Z","time spent":"2.252288356s","remote":"127.0.0.1:36054","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":4572,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:29709 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:4538 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >"}
{"level":"warn","ts":"2025-03-12T13:21:58.312605Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"436.195543ms","expected-duration":"100ms","prefix":"","request":"header:<ID:10324103616748530708 > lease_revoke:<id:0f46958a3c9f2bee>","response":"size:28"}
{"level":"info","ts":"2025-03-12T13:21:58.358497Z","caller":"traceutil/trace.go:171","msg":"trace[1088488074] transaction","detail":"{read_only:false; number_of_response:1; response_revision:29916; }","duration":"757.478646ms","start":"2025-03-12T13:21:57.600925Z","end":"2025-03-12T13:21:58.358404Z","steps":["trace[1088488074] 'process raft request'  (duration: 757.301125ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:58.363090Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:57.600808Z","time spent":"761.981699ms","remote":"127.0.0.1:60444","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":41,"response count":0,"response size":38,"request content":"compare:<target:MOD key:\"/registry/masterleases/192.168.59.100\" mod_revision:29912 > success:<request_put:<key:\"/registry/masterleases/192.168.59.100\" value_size:67 lease:1100731579893754897 >> failure:<request_range:<key:\"/registry/masterleases/192.168.59.100\" > >"}
{"level":"info","ts":"2025-03-12T13:21:58.364739Z","caller":"traceutil/trace.go:171","msg":"trace[932337196] linearizableReadLoop","detail":"{readStateIndex:40231; appliedIndex:40229; }","duration":"1.97564176s","start":"2025-03-12T13:21:56.389045Z","end":"2025-03-12T13:21:58.364687Z","steps":["trace[932337196] 'read index received'  (duration: 712.245861ms)","trace[932337196] 'applied index is now lower than readState.Index'  (duration: 1.263391113s)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:21:58.370099Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.111015337s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/minions/\" range_end:\"/registry/minions0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-12T13:21:58.370384Z","caller":"traceutil/trace.go:171","msg":"trace[812259378] range","detail":"{range_begin:/registry/minions/; range_end:/registry/minions0; response_count:0; response_revision:29916; }","duration":"2.111460844s","start":"2025-03-12T13:21:56.258788Z","end":"2025-03-12T13:21:58.370249Z","steps":["trace[812259378] 'agreement among raft nodes before linearized reading'  (duration: 2.106478466s)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:58.375569Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:56.258705Z","time spent":"2.111843508s","remote":"127.0.0.1:36054","response type":"/etcdserverpb.KV/Range","request count":0,"request size":42,"response count":1,"response size":30,"request content":"key:\"/registry/minions/\" range_end:\"/registry/minions0\" count_only:true "}
{"level":"warn","ts":"2025-03-12T13:21:58.384491Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"738.428095ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:21:58.385460Z","caller":"traceutil/trace.go:171","msg":"trace[1917960332] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:29916; }","duration":"739.405824ms","start":"2025-03-12T13:21:57.645971Z","end":"2025-03-12T13:21:58.385377Z","steps":["trace[1917960332] 'agreement among raft nodes before linearized reading'  (duration: 738.345475ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:58.411503Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"617.716373ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:21:58.412281Z","caller":"traceutil/trace.go:171","msg":"trace[1202917048] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:29916; }","duration":"626.470775ms","start":"2025-03-12T13:21:57.785726Z","end":"2025-03-12T13:21:58.412197Z","steps":["trace[1202917048] 'agreement among raft nodes before linearized reading'  (duration: 618.308691ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:58.504675Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:57.777185Z","time spent":"727.410057ms","remote":"127.0.0.1:60400","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":28,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2025-03-12T13:21:58.427879Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"673.350011ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:21:58.526429Z","caller":"traceutil/trace.go:171","msg":"trace[1906320266] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:29916; }","duration":"772.069718ms","start":"2025-03-12T13:21:57.754256Z","end":"2025-03-12T13:21:58.526326Z","steps":["trace[1906320266] 'agreement among raft nodes before linearized reading'  (duration: 673.416387ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:21:58.534813Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-12T13:21:57.754172Z","time spent":"780.530157ms","remote":"127.0.0.1:60388","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":28,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2025-03-12T13:22:05.016073Z","caller":"traceutil/trace.go:171","msg":"trace[2009530774] transaction","detail":"{read_only:false; response_revision:29921; number_of_response:1; }","duration":"191.906562ms","start":"2025-03-12T13:22:04.824089Z","end":"2025-03-12T13:22:05.015996Z","steps":["trace[2009530774] 'process raft request'  (duration: 113.385616ms)"],"step_count":1}
{"level":"info","ts":"2025-03-12T13:23:10.817709Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":29768}
{"level":"info","ts":"2025-03-12T13:23:10.874052Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":29768,"took":"51.748696ms","hash":2353709100,"current-db-size-bytes":3026944,"current-db-size":"3.0 MB","current-db-size-in-use-bytes":1720320,"current-db-size-in-use":"1.7 MB"}
{"level":"info","ts":"2025-03-12T13:23:10.874251Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":2353709100,"revision":29768,"compact-revision":29531}
{"level":"warn","ts":"2025-03-12T13:25:50.615822Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"186.205114ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:25:50.616540Z","caller":"traceutil/trace.go:171","msg":"trace[269768852] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:30087; }","duration":"187.362711ms","start":"2025-03-12T13:25:50.428912Z","end":"2025-03-12T13:25:50.616275Z","steps":["trace[269768852] 'agreement among raft nodes before linearized reading'  (duration: 23.05754ms)","trace[269768852] 'range keys from in-memory index tree'  (duration: 163.180955ms)"],"step_count":2}
{"level":"info","ts":"2025-03-12T13:27:37.503719Z","caller":"traceutil/trace.go:171","msg":"trace[1866379612] linearizableReadLoop","detail":"{readStateIndex:40557; appliedIndex:40557; }","duration":"168.019044ms","start":"2025-03-12T13:27:37.325605Z","end":"2025-03-12T13:27:37.493624Z","steps":["trace[1866379612] 'read index received'  (duration: 167.998526ms)","trace[1866379612] 'applied index is now lower than readState.Index'  (duration: 16.099¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:27:37.507906Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"182.264969ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods\" limit:1 ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:27:37.561329Z","caller":"traceutil/trace.go:171","msg":"trace[56634019] range","detail":"{range_begin:/registry/pods; range_end:; response_count:0; response_revision:30166; }","duration":"259.944537ms","start":"2025-03-12T13:27:37.301053Z","end":"2025-03-12T13:27:37.560997Z","steps":["trace[56634019] 'agreement among raft nodes before linearized reading'  (duration: 206.611953ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-12T13:27:37.614088Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"286.899747ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:27:37.617043Z","caller":"traceutil/trace.go:171","msg":"trace[2049164969] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:30167; }","duration":"289.889121ms","start":"2025-03-12T13:27:37.327039Z","end":"2025-03-12T13:27:37.616928Z","steps":["trace[2049164969] 'agreement among raft nodes before linearized reading'  (duration: 214.993625ms)","trace[2049164969] 'range keys from in-memory index tree'  (duration: 71.847371ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:27:37.652843Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"147.352912ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" limit:1 ","response":"range_response_count:1 size:1112"}
{"level":"info","ts":"2025-03-12T13:27:37.659882Z","caller":"traceutil/trace.go:171","msg":"trace[1051121749] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:30167; }","duration":"154.798687ms","start":"2025-03-12T13:27:37.504944Z","end":"2025-03-12T13:27:37.659743Z","steps":["trace[1051121749] 'agreement among raft nodes before linearized reading'  (duration: 84.026983ms)","trace[1051121749] 'range keys from in-memory index tree'  (duration: 63.589237ms)"],"step_count":2}
{"level":"info","ts":"2025-03-12T13:28:04.534856Z","caller":"traceutil/trace.go:171","msg":"trace[1122666063] transaction","detail":"{read_only:false; response_revision:30188; number_of_response:1; }","duration":"129.565754ms","start":"2025-03-12T13:28:04.404823Z","end":"2025-03-12T13:28:04.534389Z","steps":["trace[1122666063] 'process raft request'  (duration: 105.104632ms)","trace[1122666063] 'compare'  (duration: 23.275149ms)"],"step_count":2}
{"level":"info","ts":"2025-03-12T13:28:10.891788Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":29964}
{"level":"info","ts":"2025-03-12T13:28:10.972986Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":29964,"took":"67.390319ms","hash":3623337938,"current-db-size-bytes":3026944,"current-db-size":"3.0 MB","current-db-size-in-use-bytes":1568768,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-03-12T13:28:10.973314Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":3623337938,"revision":29964,"compact-revision":29768}
{"level":"info","ts":"2025-03-12T13:28:22.445159Z","caller":"traceutil/trace.go:171","msg":"trace[1003572483] transaction","detail":"{read_only:false; response_revision:30201; number_of_response:1; }","duration":"149.301995ms","start":"2025-03-12T13:28:22.295705Z","end":"2025-03-12T13:28:22.445007Z","steps":["trace[1003572483] 'process raft request'  (duration: 135.4778ms)"],"step_count":1}
{"level":"info","ts":"2025-03-12T13:29:07.108070Z","caller":"traceutil/trace.go:171","msg":"trace[855494807] transaction","detail":"{read_only:false; response_revision:30235; number_of_response:1; }","duration":"135.932864ms","start":"2025-03-12T13:29:06.971893Z","end":"2025-03-12T13:29:07.107826Z","steps":["trace[855494807] 'process raft request'  (duration: 54.081138ms)","trace[855494807] 'store kv pair into bolt db' {req_type:put; key:/registry/leases/kube-node-lease/minikube; req_size:518; } (duration: 72.57742ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-12T13:29:50.497920Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"111.518233ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-12T13:29:50.499215Z","caller":"traceutil/trace.go:171","msg":"trace[1259315855] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:30268; }","duration":"112.969128ms","start":"2025-03-12T13:29:50.386101Z","end":"2025-03-12T13:29:50.499071Z","steps":["trace[1259315855] 'agreement among raft nodes before linearized reading'  (duration: 54.527052ms)","trace[1259315855] 'range keys from in-memory index tree'  (duration: 57.045454ms)"],"step_count":2}
{"level":"info","ts":"2025-03-12T13:29:55.069710Z","caller":"traceutil/trace.go:171","msg":"trace[78808053] transaction","detail":"{read_only:false; response_revision:30271; number_of_response:1; }","duration":"101.761707ms","start":"2025-03-12T13:29:54.967848Z","end":"2025-03-12T13:29:55.069610Z","steps":["trace[78808053] 'process raft request'  (duration: 46.73313ms)","trace[78808053] 'compare'  (duration: 26.550107ms)"],"step_count":2}


==> etcd [b4dc10883aec] <==
{"level":"info","ts":"2025-02-16T17:35:43.618212Z","caller":"traceutil/trace.go:171","msg":"trace[1071155073] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"319.91762ms","start":"2025-02-16T17:35:42.308621Z","end":"2025-02-16T17:35:42.628539Z","steps":["trace[1071155073] 'agreement among raft nodes before linearized reading'  (duration: 298.160295ms)","trace[1071155073] 'get authentication metadata'  (duration: 20.616764ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:35:43.681432Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"681.683672ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/csidrivers/\" range_end:\"/registry/csidrivers0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:35:43.784470Z","caller":"traceutil/trace.go:171","msg":"trace[1423474402] range","detail":"{range_begin:/registry/csidrivers/; range_end:/registry/csidrivers0; response_count:0; response_revision:26591; }","duration":"773.316767ms","start":"2025-02-16T17:35:42.999443Z","end":"2025-02-16T17:35:43.772760Z","steps":["trace[1423474402] 'agreement among raft nodes before linearized reading'  (duration: 591.998157ms)","trace[1423474402] 'count revisions from in-memory index tree'  (duration: 89.729551ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:35:43.716604Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"210.834766ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/mutatingwebhookconfigurations/\" range_end:\"/registry/mutatingwebhookconfigurations0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:35:43.986718Z","caller":"traceutil/trace.go:171","msg":"trace[1220288433] range","detail":"{range_begin:/registry/mutatingwebhookconfigurations/; range_end:/registry/mutatingwebhookconfigurations0; response_count:0; response_revision:26591; }","duration":"480.988414ms","start":"2025-02-16T17:35:43.505447Z","end":"2025-02-16T17:35:43.986436Z","steps":["trace[1220288433] 'agreement among raft nodes before linearized reading'  (duration: 110.360872ms)","trace[1220288433] 'get authentication metadata'  (duration: 99.874071ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:35:43.991587Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:35:43.505308Z","time spent":"486.13827ms","remote":"127.0.0.1:46080","response type":"/etcdserverpb.KV/Range","request count":0,"request size":86,"response count":0,"response size":28,"request content":"key:\"/registry/mutatingwebhookconfigurations/\" range_end:\"/registry/mutatingwebhookconfigurations0\" count_only:true "}
{"level":"warn","ts":"2025-02-16T17:35:43.877800Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:35:42.999314Z","time spent":"878.319992ms","remote":"127.0.0.1:36804","response type":"/etcdserverpb.KV/Range","request count":0,"request size":48,"response count":0,"response size":28,"request content":"key:\"/registry/csidrivers/\" range_end:\"/registry/csidrivers0\" count_only:true "}
{"level":"info","ts":"2025-02-16T17:35:44.365524Z","caller":"traceutil/trace.go:171","msg":"trace[349856700] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"100.445707ms","start":"2025-02-16T17:35:44.264914Z","end":"2025-02-16T17:35:44.365360Z","steps":["trace[349856700] 'get authentication metadata'  (duration: 100.342287ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:36:02.539370Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"240.355909ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:02.539764Z","caller":"traceutil/trace.go:171","msg":"trace[17983829] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"268.744912ms","start":"2025-02-16T17:36:02.270902Z","end":"2025-02-16T17:36:02.539647Z","steps":["trace[17983829] 'agreement among raft nodes before linearized reading'  (duration: 239.949177ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:36:03.475847Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"104.290806ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:03.516343Z","caller":"traceutil/trace.go:171","msg":"trace[1919404870] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"133.380238ms","start":"2025-02-16T17:36:03.371251Z","end":"2025-02-16T17:36:03.504632Z","steps":["trace[1919404870] 'agreement among raft nodes before linearized reading'  (duration: 104.167234ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:36:04.365636Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"183.932214ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:04.411581Z","caller":"traceutil/trace.go:171","msg":"trace[1717842744] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"229.899925ms","start":"2025-02-16T17:36:04.181546Z","end":"2025-02-16T17:36:04.411446Z","steps":["trace[1717842744] 'agreement among raft nodes before linearized reading'  (duration: 76.078066ms)","trace[1717842744] 'range keys from in-memory index tree'  (duration: 95.68475ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:36:04.942652Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"148.205393ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ranges/servicenodeports\" limit:1 ","response":"range_response_count:1 size:119"}
{"level":"info","ts":"2025-02-16T17:36:04.943584Z","caller":"traceutil/trace.go:171","msg":"trace[1943204100] range","detail":"{range_begin:/registry/ranges/servicenodeports; range_end:; response_count:1; response_revision:26591; }","duration":"171.569487ms","start":"2025-02-16T17:36:04.771848Z","end":"2025-02-16T17:36:04.943418Z","steps":["trace[1943204100] 'agreement among raft nodes before linearized reading'  (duration: 93.711255ms)","trace[1943204100] 'range keys from bolt db'  (duration: 61.070632ms)"],"step_count":2}
{"level":"info","ts":"2025-02-16T17:36:33.396170Z","caller":"traceutil/trace.go:171","msg":"trace[1852714813] linearizableReadLoop","detail":"{readStateIndex:35929; appliedIndex:35929; }","duration":"109.818745ms","start":"2025-02-16T17:36:33.285900Z","end":"2025-02-16T17:36:33.395719Z","steps":["trace[1852714813] 'read index received'  (duration: 35.033869ms)","trace[1852714813] 'applied index is now lower than readState.Index'  (duration: 74.777987ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:36:33.413259Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"126.955925ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:33.445490Z","caller":"traceutil/trace.go:171","msg":"trace[52664224] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"159.547994ms","start":"2025-02-16T17:36:33.285849Z","end":"2025-02-16T17:36:33.445397Z","steps":["trace[52664224] 'agreement among raft nodes before linearized reading'  (duration: 126.428238ms)"],"step_count":1}
{"level":"info","ts":"2025-02-16T17:36:34.449519Z","caller":"traceutil/trace.go:171","msg":"trace[194518819] linearizableReadLoop","detail":"{readStateIndex:35929; appliedIndex:35929; }","duration":"176.420943ms","start":"2025-02-16T17:36:34.272980Z","end":"2025-02-16T17:36:34.449401Z","steps":["trace[194518819] 'read index received'  (duration: 176.374368ms)","trace[194518819] 'applied index is now lower than readState.Index'  (duration: 23.033¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:36:34.509604Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"236.530653ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:34.518467Z","caller":"traceutil/trace.go:171","msg":"trace[1273906656] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"245.397167ms","start":"2025-02-16T17:36:34.272918Z","end":"2025-02-16T17:36:34.518315Z","steps":["trace[1273906656] 'agreement among raft nodes before linearized reading'  (duration: 214.394525ms)","trace[1273906656] 'range keys from in-memory index tree'  (duration: 21.9975ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:36:42.073604Z","caller":"etcdserver/v3_server.go:920","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":10324103016315597768,"retry-timeout":"500ms"}
{"level":"warn","ts":"2025-02-16T17:36:42.113277Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"560.684811ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:42.625325Z","caller":"traceutil/trace.go:171","msg":"trace[126411413] linearizableReadLoop","detail":"{readStateIndex:35929; appliedIndex:35929; }","duration":"1.067584069s","start":"2025-02-16T17:36:41.552072Z","end":"2025-02-16T17:36:42.619656Z","steps":["trace[126411413] 'read index received'  (duration: 522.688894ms)","trace[126411413] 'applied index is now lower than readState.Index'  (duration: 21.569¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:36:42.677582Z","caller":"etcdserver/v3_server.go:897","msg":"ignored out-of-date read index response; local node read indexes queueing up and waiting to be in sync with leader","sent-request-id":10324103016315597769,"received-request-id":10324103016315597768}
{"level":"info","ts":"2025-02-16T17:36:42.677846Z","caller":"traceutil/trace.go:171","msg":"trace[703963406] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"561.777186ms","start":"2025-02-16T17:36:41.552022Z","end":"2025-02-16T17:36:42.113800Z","steps":["trace[703963406] 'agreement among raft nodes before linearized reading'  (duration: 560.555356ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:36:42.679185Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:36:41.895297Z","time spent":"783.778125ms","remote":"127.0.0.1:48872","response type":"/etcdserverpb.KV/Range","request count":0,"request size":52,"response count":0,"response size":28,"request content":"key:\"/registry/podtemplates/\" range_end:\"/registry/podtemplates0\" count_only:true "}
{"level":"warn","ts":"2025-02-16T17:36:42.961721Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"329.677793ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/validatingwebhookconfigurations/\" range_end:\"/registry/validatingwebhookconfigurations0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:36:42.966035Z","caller":"traceutil/trace.go:171","msg":"trace[1041084017] range","detail":"{range_begin:/registry/validatingwebhookconfigurations/; range_end:/registry/validatingwebhookconfigurations0; response_count:0; response_revision:26591; }","duration":"354.137125ms","start":"2025-02-16T17:36:42.611455Z","end":"2025-02-16T17:36:42.965592Z","steps":["trace[1041084017] 'agreement among raft nodes before linearized reading'  (duration: 95.205967ms)","trace[1041084017] 'get authentication metadata'  (duration: 202.920137ms)","trace[1041084017] 'count revisions from in-memory index tree'  (duration: 34.392457ms)"],"step_count":3}
{"level":"warn","ts":"2025-02-16T17:36:42.966584Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:36:42.607762Z","time spent":"358.526402ms","remote":"127.0.0.1:46076","response type":"/etcdserverpb.KV/Range","request count":0,"request size":90,"response count":0,"response size":28,"request content":"key:\"/registry/validatingwebhookconfigurations/\" range_end:\"/registry/validatingwebhookconfigurations0\" count_only:true "}
{"level":"warn","ts":"2025-02-16T17:36:50.229461Z","caller":"embed/config_logging.go:170","msg":"rejected connection on client endpoint","remote-addr":"127.0.0.1:53374","server-name":"","error":"EOF"}
{"level":"warn","ts":"2025-02-16T17:37:01.413415Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"114.703484ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:37:01.414469Z","caller":"traceutil/trace.go:171","msg":"trace[655412984] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"115.799699ms","start":"2025-02-16T17:37:01.298585Z","end":"2025-02-16T17:37:01.414385Z","steps":["trace[655412984] 'agreement among raft nodes before linearized reading'  (duration: 87.116228ms)"],"step_count":1}
{"level":"info","ts":"2025-02-16T17:43:16.831286Z","caller":"traceutil/trace.go:171","msg":"trace[1931874813] range","detail":"{range_begin:/registry/pods/; range_end:/registry/pods0; response_count:0; response_revision:26591; }","duration":"115.867705ms","start":"2025-02-16T17:43:16.715021Z","end":"2025-02-16T17:43:16.830888Z","steps":["trace[1931874813] 'agreement among raft nodes before linearized reading'  (duration: 49.773075ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:43:20.615420Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"150.918216ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/controllers/\" range_end:\"/registry/controllers0\" limit:10000 ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:43:20.616310Z","caller":"traceutil/trace.go:171","msg":"trace[1645624036] range","detail":"{range_begin:/registry/controllers/; range_end:/registry/controllers0; response_count:0; response_revision:26591; }","duration":"151.865459ms","start":"2025-02-16T17:43:20.464208Z","end":"2025-02-16T17:43:20.616073Z","steps":["trace[1645624036] 'agreement among raft nodes before linearized reading'  (duration: 90.828803ms)","trace[1645624036] 'range keys from in-memory index tree'  (duration: 57.477894ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:43:28.221389Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"118.533467ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/certificatesigningrequests/\" range_end:\"/registry/certificatesigningrequests0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:43:28.221888Z","caller":"traceutil/trace.go:171","msg":"trace[2055584271] range","detail":"{range_begin:/registry/certificatesigningrequests/; range_end:/registry/certificatesigningrequests0; response_count:0; response_revision:26591; }","duration":"119.4436ms","start":"2025-02-16T17:43:28.102330Z","end":"2025-02-16T17:43:28.221773Z","steps":["trace[2055584271] 'agreement among raft nodes before linearized reading'  (duration: 19.465771ms)","trace[2055584271] 'count revisions from in-memory index tree'  (duration: 75.505051ms)"],"step_count":2}
{"level":"info","ts":"2025-02-16T17:43:32.840116Z","caller":"traceutil/trace.go:171","msg":"trace[188391614] linearizableReadLoop","detail":"{readStateIndex:35932; appliedIndex:35932; }","duration":"130.107229ms","start":"2025-02-16T17:43:32.709436Z","end":"2025-02-16T17:43:32.839543Z","steps":["trace[188391614] 'read index received'  (duration: 130.066621ms)","trace[188391614] 'applied index is now lower than readState.Index'  (duration: 33.888¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:43:32.872429Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"131.185298ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/runtimeclasses/\" range_end:\"/registry/runtimeclasses0\" limit:10000 ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:43:32.873529Z","caller":"traceutil/trace.go:171","msg":"trace[1886338481] range","detail":"{range_begin:/registry/runtimeclasses/; range_end:/registry/runtimeclasses0; response_count:0; response_revision:26591; }","duration":"190.856578ms","start":"2025-02-16T17:43:32.682431Z","end":"2025-02-16T17:43:32.873287Z","steps":["trace[1886338481] 'agreement among raft nodes before linearized reading'  (duration: 157.972821ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:43:37.096821Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"282.409141ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/clusterrolebindings/\" range_end:\"/registry/clusterrolebindings0\" limit:10000 ","response":"range_response_count:54 size:38342"}
{"level":"info","ts":"2025-02-16T17:43:37.153262Z","caller":"traceutil/trace.go:171","msg":"trace[643936281] range","detail":"{range_begin:/registry/clusterrolebindings/; range_end:/registry/clusterrolebindings0; response_count:54; response_revision:26591; }","duration":"294.550903ms","start":"2025-02-16T17:43:36.803283Z","end":"2025-02-16T17:43:37.097834Z","steps":["trace[643936281] 'range keys from in-memory index tree'  (duration: 39.860845ms)","trace[643936281] 'range keys from bolt db'  (duration: 241.219475ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:43:37.154613Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:43:36.802543Z","time spent":"351.237306ms","remote":"127.0.0.1:53124","response type":"/etcdserverpb.KV/Range","request count":0,"request size":67,"response count":54,"response size":38364,"request content":"key:\"/registry/clusterrolebindings/\" range_end:\"/registry/clusterrolebindings0\" limit:10000 "}
{"level":"info","ts":"2025-02-16T17:43:41.473459Z","caller":"traceutil/trace.go:171","msg":"trace[156108978] linearizableReadLoop","detail":"{readStateIndex:35932; appliedIndex:35932; }","duration":"100.735339ms","start":"2025-02-16T17:43:41.372579Z","end":"2025-02-16T17:43:41.473316Z","steps":["trace[156108978] 'read index received'  (duration: 100.672653ms)","trace[156108978] 'applied index is now lower than readState.Index'  (duration: 55.846¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:43:41.583807Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"211.132777ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/volumeattachments/\" range_end:\"/registry/volumeattachments0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:43:41.584860Z","caller":"traceutil/trace.go:171","msg":"trace[773170573] range","detail":"{range_begin:/registry/volumeattachments/; range_end:/registry/volumeattachments0; response_count:0; response_revision:26591; }","duration":"212.869474ms","start":"2025-02-16T17:43:41.371783Z","end":"2025-02-16T17:43:41.584653Z","steps":["trace[773170573] 'agreement among raft nodes before linearized reading'  (duration: 129.659659ms)","trace[773170573] 'get authentication metadata'  (duration: 81.975232ms)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:43:41.651652Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"247.631292ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/volumeattachments/\" range_end:\"/registry/volumeattachments0\" limit:10000 ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:43:41.684560Z","caller":"traceutil/trace.go:171","msg":"trace[1794745260] range","detail":"{range_begin:/registry/volumeattachments/; range_end:/registry/volumeattachments0; response_count:0; response_revision:26591; }","duration":"280.500856ms","start":"2025-02-16T17:43:41.403667Z","end":"2025-02-16T17:43:41.684168Z","steps":["trace[1794745260] 'agreement among raft nodes before linearized reading'  (duration: 247.022997ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:43:41.756340Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:43:41.403062Z","time spent":"353.093043ms","remote":"127.0.0.1:53148","response type":"/etcdserverpb.KV/Range","request count":0,"request size":63,"response count":0,"response size":28,"request content":"key:\"/registry/volumeattachments/\" range_end:\"/registry/volumeattachments0\" limit:10000 "}
{"level":"warn","ts":"2025-02-16T17:43:53.291268Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"223.42752ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/controllerrevisions/\" range_end:\"/registry/controllerrevisions0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-02-16T17:43:53.310100Z","caller":"traceutil/trace.go:171","msg":"trace[129046102] range","detail":"{range_begin:/registry/controllerrevisions/; range_end:/registry/controllerrevisions0; response_count:0; response_revision:26591; }","duration":"224.266411ms","start":"2025-02-16T17:43:53.067519Z","end":"2025-02-16T17:43:53.291785Z","steps":["trace[129046102] 'agreement among raft nodes before linearized reading'  (duration: 108.943749ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:43:53.429453Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:43:53.067272Z","time spent":"362.028508ms","remote":"127.0.0.1:48294","response type":"/etcdserverpb.KV/Range","request count":0,"request size":66,"response count":1,"response size":30,"request content":"key:\"/registry/controllerrevisions/\" range_end:\"/registry/controllerrevisions0\" count_only:true "}
{"level":"info","ts":"2025-02-16T17:43:55.060761Z","caller":"traceutil/trace.go:171","msg":"trace[305624171] linearizableReadLoop","detail":"{readStateIndex:35932; appliedIndex:35932; }","duration":"113.882386ms","start":"2025-02-16T17:43:54.946744Z","end":"2025-02-16T17:43:55.060627Z","steps":["trace[305624171] 'read index received'  (duration: 113.813545ms)","trace[305624171] 'applied index is now lower than readState.Index'  (duration: 48.209¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-02-16T17:43:55.078405Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"131.582463ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/validatingwebhookconfigurations/\" range_end:\"/registry/validatingwebhookconfigurations0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:43:55.106343Z","caller":"traceutil/trace.go:171","msg":"trace[1594429339] range","detail":"{range_begin:/registry/validatingwebhookconfigurations/; range_end:/registry/validatingwebhookconfigurations0; response_count:0; response_revision:26591; }","duration":"250.758574ms","start":"2025-02-16T17:43:54.827936Z","end":"2025-02-16T17:43:55.078693Z","steps":["trace[1594429339] 'agreement among raft nodes before linearized reading'  (duration: 250.116878ms)"],"step_count":1}
{"level":"warn","ts":"2025-02-16T17:43:55.228457Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-02-16T17:43:54.827676Z","time spent":"346.05268ms","remote":"127.0.0.1:49110","response type":"/etcdserverpb.KV/Range","request count":0,"request size":90,"response count":0,"response size":28,"request content":"key:\"/registry/validatingwebhookconfigurations/\" range_end:\"/registry/validatingwebhookconfigurations0\" count_only:true "}
{"level":"warn","ts":"2025-02-16T17:44:09.375581Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"115.05782ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-02-16T17:44:09.425229Z","caller":"traceutil/trace.go:171","msg":"trace[564947341] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:26591; }","duration":"164.389958ms","start":"2025-02-16T17:44:09.260369Z","end":"2025-02-16T17:44:09.424759Z","steps":["trace[564947341] 'agreement among raft nodes before linearized reading'  (duration: 22.345421ms)","trace[564947341] 'filter and sort the key-value pairs'  (duration: 92.467635ms)"],"step_count":2}


==> kernel <==
 13:30:34 up  1:33,  0 users,  load average: 14.64, 11.30, 11.36
Linux minikube 5.10.207 #1 SMP Tue Jan 14 08:15:54 UTC 2025 x86_64 GNU/Linux
PRETTY_NAME="Buildroot 2023.02.9"


==> kube-apiserver [9608b9305184] <==
E0312 12:46:36.312640       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:46:36.466527       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:46:36.625438       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 340.628479ms, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0312 12:46:36.684381       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="361.380952ms" method="PUT" path="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" result=null
E0312 12:49:40.920748       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 41.639¬µs, panicked: false, err: context deadline exceeded, panic-reason: <nil>" logger="UnhandledError"
E0312 12:49:40.961237       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:49:40.985273       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:49:40.986861       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:49:41.058013       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="130.519531ms" method="PUT" path="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result=null
E0312 12:49:46.410818       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:49:46.411303       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 46.282¬µs, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0312 12:49:46.412540       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:49:46.417058       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:49:46.476195       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="66.6484ms" method="POST" path="/api/v1/namespaces/default/events" result=null
W0312 12:50:03.077339       1 logging.go:55] [core] [Channel #394 SubChannel #395]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "error reading server preface: read tcp 127.0.0.1:38890->127.0.0.1:2379: use of closed network connection"
E0312 12:50:07.171640       1 controller.go:163] "Unhandled Error" err="unable to sync kubernetes service: no API server IP addresses were listed in storage, refusing to erase all endpoints for the kubernetes Service" logger="UnhandledError"
E0312 12:50:19.716050       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="6.750075742s" method="GET" path="/readyz" result=null
E0312 12:50:21.565110       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:21.566021       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 91.927¬µs, panicked: false, err: context deadline exceeded, panic-reason: <nil>" logger="UnhandledError"
E0312 12:50:21.566914       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:50:21.568483       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:21.570385       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="3.225062ms" method="PUT" path="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result=null
E0312 12:50:23.033571       1 controller.go:163] "Unhandled Error" err="unable to sync kubernetes service: etcdserver: request timed out" logger="UnhandledError"
E0312 12:50:29.576641       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:29.614563       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:50:29.637717       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:29.892621       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="774.550169ms" method="PATCH" path="/api/v1/nodes/minikube/status" result=null
E0312 12:50:31.663267       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 131.28¬µs, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0312 12:50:31.666270       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:31.671800       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:50:31.674356       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:31.677539       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="166.753105ms" method="PUT" path="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result=null
E0312 12:50:32.434571       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="1.05487822s" method="GET" path="/readyz" result=null
E0312 12:50:35.290166       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 6.209355901s, panicked: false, err: context deadline exceeded, panic-reason: <nil>" logger="UnhandledError"
W0312 12:50:30.469307       1 logging.go:55] [core] [Channel #397 SubChannel #398]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: failed to write client preface: write tcp 127.0.0.1:58538->127.0.0.1:2379: use of closed network connection"
E0312 12:50:30.979259       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0312 12:50:31.014016       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:31.025453       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:50:31.044608       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:31.047945       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="68.242729ms" method="GET" path="/api/v1/nodes/minikube" result=null
E0312 12:50:46.912152       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 45.171¬µs, panicked: false, err: context deadline exceeded, panic-reason: <nil>" logger="UnhandledError"
E0312 12:50:47.636033       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:47.653944       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 12:50:47.709950       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 12:50:47.816116       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="932.863515ms" method="PUT" path="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result=null
E0312 12:51:09.626258       1 controller.go:163] "Unhandled Error" err="unable to sync kubernetes service: no API server IP addresses were listed in storage, refusing to erase all endpoints for the kubernetes Service" logger="UnhandledError"
I0312 13:08:29.633595       1 alloc.go:330] "allocated clusterIPs" service="default/serviceadmin" clusterIPs={"IPv4":"10.101.141.3"}
I0312 13:08:48.710333       1 alloc.go:330] "allocated clusterIPs" service="default/my-node-app-service" clusterIPs={"IPv4":"10.106.78.118"}
E0312 13:11:02.090054       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0312 13:11:02.102773       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0312 13:11:02.117097       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0312 13:11:02.198211       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="15.883¬µs" method="PUT" path="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" result=null
E0312 13:11:02.250909       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 160.193645ms, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
I0312 13:12:52.633901       1 controller.go:615] quota admission added evaluator for: namespaces
I0312 13:13:05.383372       1 alloc.go:330] "allocated clusterIPs" service="ingress-nginx/ingress-nginx-controller" clusterIPs={"IPv4":"10.102.160.225"}
I0312 13:13:07.126248       1 alloc.go:330] "allocated clusterIPs" service="ingress-nginx/ingress-nginx-controller-admission" clusterIPs={"IPv4":"10.107.71.11"}
I0312 13:13:08.715843       1 controller.go:615] quota admission added evaluator for: jobs.batch
E0312 13:21:53.894142       1 wrap.go:53] "Timeout or abort while handling" logger="UnhandledError" method="PUT" URI="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" auditID="b07f510d-2fc2-4be1-b6b1-7c3f7f55022b"
E0312 13:21:53.993075       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="86.738565ms" method="PUT" path="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" result=null
E0312 13:21:54.169814       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 263.900393ms, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"


==> kube-apiserver [c68df857a62e] <==
I0216 17:43:01.525504       1 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
I0216 17:43:01.967361       1 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
I0216 17:43:01.967870       1 plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
I0216 17:43:01.979573       1 instance.go:233] Using reconciler: lease
I0216 17:43:04.858601       1 handler.go:286] Adding GroupVersion apiextensions.k8s.io v1 to ResourceManager
W0216 17:43:04.866254       1 genericapiserver.go:767] Skipping API apiextensions.k8s.io/v1beta1 because it has no resources.
I0216 17:43:24.928527       1 handler.go:286] Adding GroupVersion  v1 to ResourceManager
I0216 17:43:24.943596       1 apis.go:106] API group "internal.apiserver.k8s.io" is not enabled, skipping.
I0216 17:43:44.500733       1 apis.go:106] API group "storagemigration.k8s.io" is not enabled, skipping.
I0216 17:44:00.827754       1 apis.go:106] API group "resource.k8s.io" is not enabled, skipping.
I0216 17:44:02.528444       1 handler.go:286] Adding GroupVersion authentication.k8s.io v1 to ResourceManager
W0216 17:44:02.530313       1 genericapiserver.go:767] Skipping API authentication.k8s.io/v1beta1 because it has no resources.
W0216 17:44:02.531827       1 genericapiserver.go:767] Skipping API authentication.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:02.635792       1 handler.go:286] Adding GroupVersion authorization.k8s.io v1 to ResourceManager
W0216 17:44:02.652322       1 genericapiserver.go:767] Skipping API authorization.k8s.io/v1beta1 because it has no resources.
I0216 17:44:02.721397       1 handler.go:286] Adding GroupVersion autoscaling v2 to ResourceManager
I0216 17:44:02.747607       1 handler.go:286] Adding GroupVersion autoscaling v1 to ResourceManager
W0216 17:44:02.755749       1 genericapiserver.go:767] Skipping API autoscaling/v2beta1 because it has no resources.
W0216 17:44:02.756443       1 genericapiserver.go:767] Skipping API autoscaling/v2beta2 because it has no resources.
I0216 17:44:03.091228       1 handler.go:286] Adding GroupVersion batch v1 to ResourceManager
W0216 17:44:03.091720       1 genericapiserver.go:767] Skipping API batch/v1beta1 because it has no resources.
I0216 17:44:03.190471       1 handler.go:286] Adding GroupVersion certificates.k8s.io v1 to ResourceManager
W0216 17:44:03.195699       1 genericapiserver.go:767] Skipping API certificates.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.199051       1 genericapiserver.go:767] Skipping API certificates.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:03.336159       1 handler.go:286] Adding GroupVersion coordination.k8s.io v1 to ResourceManager
W0216 17:44:03.336383       1 genericapiserver.go:767] Skipping API coordination.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.336472       1 genericapiserver.go:767] Skipping API coordination.k8s.io/v1alpha2 because it has no resources.
I0216 17:44:03.388351       1 handler.go:286] Adding GroupVersion discovery.k8s.io v1 to ResourceManager
W0216 17:44:03.391042       1 genericapiserver.go:767] Skipping API discovery.k8s.io/v1beta1 because it has no resources.
I0216 17:44:03.478258       1 handler.go:286] Adding GroupVersion networking.k8s.io v1 to ResourceManager
W0216 17:44:03.479503       1 genericapiserver.go:767] Skipping API networking.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.480223       1 genericapiserver.go:767] Skipping API networking.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:03.502234       1 handler.go:286] Adding GroupVersion node.k8s.io v1 to ResourceManager
W0216 17:44:03.502647       1 genericapiserver.go:767] Skipping API node.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.502809       1 genericapiserver.go:767] Skipping API node.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:03.565967       1 handler.go:286] Adding GroupVersion policy v1 to ResourceManager
W0216 17:44:03.568200       1 genericapiserver.go:767] Skipping API policy/v1beta1 because it has no resources.
I0216 17:44:03.727522       1 handler.go:286] Adding GroupVersion rbac.authorization.k8s.io v1 to ResourceManager
W0216 17:44:03.728862       1 genericapiserver.go:767] Skipping API rbac.authorization.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.731826       1 genericapiserver.go:767] Skipping API rbac.authorization.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:03.753446       1 handler.go:286] Adding GroupVersion scheduling.k8s.io v1 to ResourceManager
W0216 17:44:03.756653       1 genericapiserver.go:767] Skipping API scheduling.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.757773       1 genericapiserver.go:767] Skipping API scheduling.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:03.864332       1 handler.go:286] Adding GroupVersion storage.k8s.io v1 to ResourceManager
W0216 17:44:03.870240       1 genericapiserver.go:767] Skipping API storage.k8s.io/v1beta1 because it has no resources.
W0216 17:44:03.873644       1 genericapiserver.go:767] Skipping API storage.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:03.949591       1 handler.go:286] Adding GroupVersion flowcontrol.apiserver.k8s.io v1 to ResourceManager
W0216 17:44:03.956661       1 genericapiserver.go:767] Skipping API flowcontrol.apiserver.k8s.io/v1beta3 because it has no resources.
W0216 17:44:03.957675       1 genericapiserver.go:767] Skipping API flowcontrol.apiserver.k8s.io/v1beta2 because it has no resources.
W0216 17:44:03.958436       1 genericapiserver.go:767] Skipping API flowcontrol.apiserver.k8s.io/v1beta1 because it has no resources.
I0216 17:44:04.235335       1 handler.go:286] Adding GroupVersion apps v1 to ResourceManager
W0216 17:44:04.239126       1 genericapiserver.go:767] Skipping API apps/v1beta2 because it has no resources.
W0216 17:44:04.241372       1 genericapiserver.go:767] Skipping API apps/v1beta1 because it has no resources.
I0216 17:44:04.371796       1 handler.go:286] Adding GroupVersion admissionregistration.k8s.io v1 to ResourceManager
W0216 17:44:04.374747       1 genericapiserver.go:767] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
W0216 17:44:04.379490       1 genericapiserver.go:767] Skipping API admissionregistration.k8s.io/v1alpha1 because it has no resources.
I0216 17:44:04.408086       1 handler.go:286] Adding GroupVersion events.k8s.io v1 to ResourceManager
W0216 17:44:04.412635       1 genericapiserver.go:767] Skipping API events.k8s.io/v1beta1 because it has no resources.
I0216 17:44:06.133203       1 handler.go:286] Adding GroupVersion apiregistration.k8s.io v1 to ResourceManager
W0216 17:44:06.133480       1 genericapiserver.go:767] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.


==> kube-controller-manager [5ea32f339a34] <==
I0312 12:02:58.784062       1 serving.go:386] Generated self-signed cert in-memory
I0312 12:03:41.034402       1 controllermanager.go:185] "Starting" version="v1.32.0"
I0312 12:03:41.035149       1 controllermanager.go:187] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0312 12:03:41.152872       1 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0312 12:03:41.163788       1 dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0312 12:03:41.194772       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0312 12:03:41.218274       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
E0312 12:04:02.071671       1 controllermanager.go:230] "Error building controller context" err="failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: an error on the server (\"[+]ping ok\\n[+]log ok\\n[+]etcd ok\\n[+]poststarthook/start-apiserver-admission-initializer ok\\n[+]poststarthook/generic-apiserver-start-informers ok\\n[+]poststarthook/priority-and-fairness-config-consumer ok\\n[+]poststarthook/priority-and-fairness-filter ok\\n[+]poststarthook/storage-object-count-tracker-hook ok\\n[+]poststarthook/start-apiextensions-informers ok\\n[+]poststarthook/start-apiextensions-controllers ok\\n[+]poststarthook/crd-informer-synced ok\\n[+]poststarthook/start-system-namespaces-controller ok\\n[+]poststarthook/start-cluster-authentication-info-controller ok\\n[+]poststarthook/start-kube-apiserver-identity-lease-controller ok\\n[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok\\n[+]poststarthook/start-legacy-token-tracking-controller ok\\n[+]poststarthook/start-service-ip-repair-controllers ok\\n[-]poststarthook/rbac/bootstrap-roles failed: reason withheld\\n[+]poststarthook/scheduling/bootstrap-system-priority-classes ok\\n[+]poststarthook/priority-and-fairness-config-producer ok\\n[+]poststarthook/bootstrap-controller ok\\n[+]poststarthook/aggregator-reload-proxy-client-cert ok\\n[+]poststarthook/start-kube-aggregator-informers ok\\n[+]poststarthook/apiservice-status-local-available-controller ok\\n[+]poststarthook/apiservice-status-remote-available-controller ok\\n[-]poststarthook/apiservice-registration-controller failed: reason withheld\\n[-]poststarthook/apiservice-discovery-controller failed: reason withheld\\n[+]poststarthook/kube-apiserver-autoregistration ok\\n[+]autoregister-completion ok\\n[+]poststarthook/apiservice-openapi-controller ok\\n[+]poststarthook/apiservice-openapiv3-controller ok\\nhealthz check failed\") has prevented the request from succeeding"


==> kube-controller-manager [a071185b728c] <==
I0312 12:05:29.380773       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0312 12:05:29.381043       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0312 12:05:29.391935       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0312 12:05:29.494265       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0312 12:05:29.494857       1 shared_informer.go:320] Caches are synced for deployment
I0312 12:05:29.623723       1 shared_informer.go:320] Caches are synced for disruption
I0312 12:05:29.668440       1 shared_informer.go:320] Caches are synced for stateful set
I0312 12:05:30.005242       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0312 12:05:30.033826       1 shared_informer.go:320] Caches are synced for resource quota
I0312 12:05:30.062019       1 shared_informer.go:320] Caches are synced for resource quota
I0312 12:05:30.062930       1 shared_informer.go:320] Caches are synced for endpoint
I0312 12:05:30.300675       1 shared_informer.go:320] Caches are synced for garbage collector
I0312 12:05:30.300780       1 garbagecollector.go:154] "Garbage collector: all resource monitors have synced" logger="garbage-collector-controller"
I0312 12:05:30.300919       1 garbagecollector.go:157] "Proceeding to collect garbage" logger="garbage-collector-controller"
I0312 12:05:30.310475       1 shared_informer.go:320] Caches are synced for garbage collector
I0312 12:05:32.104163       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="2.746606423s"
I0312 12:05:32.107001       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="731.507¬µs"
I0312 12:05:43.539621       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="354.555¬µs"
I0312 12:06:31.138278       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="3.95739334s"
I0312 12:06:31.942405       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="17.096003ms"
I0312 12:09:25.031301       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:14:34.337726       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:19:42.297391       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:24:49.539056       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:29:49.883079       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:34:59.773275       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:40:12.727803       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:45:22.525070       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 12:50:48.987161       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
E0312 12:50:44.042681       1 node_lifecycle_controller.go:980] "Error updating node" err="Operation cannot be fulfilled on nodes \"minikube\": the object has been modified; please apply your changes to the latest version and try again" logger="node-lifecycle-controller" node="minikube"
I0312 12:50:50.506214       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="2.037611112s"
I0312 12:50:50.541586       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="18.433351ms"
I0312 12:51:03.636643       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="11.801402795s"
I0312 12:51:03.637665       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="524.292¬µs"
I0312 12:56:22.842187       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:01:33.694964       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:06:44.077137       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:08:30.836687       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/serviceadmin-7dc8b8788f" duration="1.367663044s"
I0312 13:08:31.690967       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/serviceadmin-7dc8b8788f" duration="853.786228ms"
I0312 13:08:31.695189       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/serviceadmin-7dc8b8788f" duration="1.004591ms"
I0312 13:11:46.765856       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:13:08.875014       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-create" delay="0s"
I0312 13:13:10.800032       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-create" delay="1s"
I0312 13:13:10.935312       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-patch" delay="0s"
I0312 13:13:12.684420       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-patch" delay="1s"
I0312 13:13:13.351696       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-create" delay="1s"
I0312 13:13:14.731059       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-patch" delay="1s"
I0312 13:13:15.571733       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-create" delay="1s"
I0312 13:13:16.279215       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-patch" delay="1s"
I0312 13:13:16.824185       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="ingress-nginx/ingress-nginx-controller-56d7c84fd4" duration="8.062125154s"
I0312 13:13:20.065936       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="ingress-nginx/ingress-nginx-controller-56d7c84fd4" duration="3.241187795s"
I0312 13:13:20.072915       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="ingress-nginx/ingress-nginx-controller-56d7c84fd4" duration="6.800287ms"
I0312 13:13:20.152861       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-create" delay="1s"
I0312 13:13:24.206179       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="ingress-nginx/ingress-nginx-controller-56d7c84fd4" duration="16.154371ms"
I0312 13:13:26.301987       1 job_controller.go:598] "enqueueing job" logger="job-controller" key="ingress-nginx/ingress-nginx-admission-patch" delay="1s"
I0312 13:16:49.627057       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:21:58.241163       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:27:07.004181       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0312 13:30:30.671824       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/serviceadmin-7dc8b8788f" duration="1.128672594s"
I0312 13:30:30.718083       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/serviceadmin-7dc8b8788f" duration="9.499303ms"


==> kube-proxy [3ede003cd8bd] <==
I0312 12:05:34.360143       1 server_linux.go:66] "Using iptables proxy"
E0312 12:05:36.566168       1 proxier.go:733] "Error cleaning up nftables rules" err=<
	could not run nftables command: /dev/stdin:1:1-24: Error: Could not process rule: Operation not supported
	add table ip kube-proxy
	^^^^^^^^^^^^^^^^^^^^^^^^
 >
E0312 12:05:37.287753       1 proxier.go:733] "Error cleaning up nftables rules" err=<
	could not run nftables command: /dev/stdin:1:1-25: Error: Could not process rule: Operation not supported
	add table ip6 kube-proxy
	^^^^^^^^^^^^^^^^^^^^^^^^^
 >
I0312 12:05:38.524667       1 server.go:698] "Successfully retrieved node IP(s)" IPs=["192.168.59.100"]
E0312 12:05:38.525242       1 server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0312 12:05:40.801735       1 server_linux.go:147] "No iptables support for family" ipFamily="IPv6"
I0312 12:05:40.805419       1 server.go:245] "kube-proxy running in single-stack mode" ipFamily="IPv4"
I0312 12:05:40.808261       1 server_linux.go:170] "Using iptables Proxier"
I0312 12:05:40.970681       1 proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0312 12:05:40.999735       1 server.go:497] "Version info" version="v1.32.0"
I0312 12:05:41.000163       1 server.go:499] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0312 12:05:41.091759       1 config.go:199] "Starting service config controller"
I0312 12:05:41.100680       1 shared_informer.go:313] Waiting for caches to sync for service config
I0312 12:05:41.107138       1 config.go:329] "Starting node config controller"
I0312 12:05:41.112139       1 shared_informer.go:313] Waiting for caches to sync for node config
I0312 12:05:41.116154       1 config.go:105] "Starting endpoint slice config controller"
I0312 12:05:41.126616       1 shared_informer.go:313] Waiting for caches to sync for endpoint slice config
I0312 12:05:41.309824       1 shared_informer.go:320] Caches are synced for service config
I0312 12:05:41.327738       1 shared_informer.go:320] Caches are synced for endpoint slice config
I0312 12:05:41.387859       1 shared_informer.go:320] Caches are synced for node config


==> kube-scheduler [4558fe70422c] <==
I0312 12:03:29.699333       1 serving.go:386] Generated self-signed cert in-memory
W0312 12:03:58.216075       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0312 12:03:58.220100       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0312 12:03:58.225336       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0312 12:03:58.230848       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0312 12:03:59.770979       1 server.go:166] "Starting Kubernetes Scheduler" version="v1.32.0"
I0312 12:03:59.771411       1 server.go:168] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0312 12:04:00.204705       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0312 12:04:00.279737       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0312 12:04:00.306150       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0312 12:04:00.365823       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0312 12:04:00.800142       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file


==> kube-scheduler [b5f6cb45bea2] <==
W0215 14:32:37.861471       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": dial tcp 192.168.59.100:8443: connect: connection refused
E0215 14:32:37.866680       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": dial tcp 192.168.59.100:8443: connect: connection refused" logger="UnhandledError"
http2: server: error reading preface from client 127.0.0.1:56948: read tcp 127.0.0.1:10259->127.0.0.1:56948: read: connection reset by peer
W0215 14:33:16.939175       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": dial tcp 192.168.59.100:8443: connect: connection refused
E0215 14:33:16.940047       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": dial tcp 192.168.59.100:8443: connect: connection refused" logger="UnhandledError"
W0215 14:34:57.209596       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:34:57.214642       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:35:53.261447       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:35:53.272766       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:36:53.805480       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:36:53.806241       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:37:20.163778       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": dial tcp 192.168.59.100:8443: connect: connection refused
E0215 14:37:20.164776       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": dial tcp 192.168.59.100:8443: connect: connection refused" logger="UnhandledError"
W0215 14:38:23.976563       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:38:23.978234       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:39:11.117883       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:39:11.125395       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:40:18.007661       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:40:18.011436       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:41:24.458108       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:41:24.464254       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:41:59.955481       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:41:59.956470       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:42:21.193460       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:42:21.447492       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:43:59.145336       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:43:59.150376       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:44:43.619889       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:44:44.897179       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:45:10.736473       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": dial tcp 192.168.59.100:8443: connect: connection refused
E0215 14:45:10.766380       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": dial tcp 192.168.59.100:8443: connect: connection refused" logger="UnhandledError"
W0215 14:45:59.921605       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:45:59.924464       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:46:51.527847       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:46:51.530825       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:47:50.598790       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:47:50.613704       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:48:51.486497       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": dial tcp 192.168.59.100:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.59.100:39586->192.168.59.100:8443: read: connection reset by peer
E0215 14:48:51.487558       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": dial tcp 192.168.59.100:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.59.100:39586->192.168.59.100:8443: read: connection reset by peer" logger="UnhandledError"
W0215 14:50:00.333265       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": dial tcp 192.168.59.100:8443: connect: connection refused
E0215 14:50:00.336070       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": dial tcp 192.168.59.100:8443: connect: connection refused" logger="UnhandledError"
W0215 14:51:15.507144       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:51:15.520996       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
W0215 14:52:14.756371       1 reflector.go:569] runtime/asm_amd64.s:1700: failed to list *v1.ConfigMap: Get "https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299": net/http: TLS handshake timeout
E0215 14:52:14.770179       1 reflector.go:166] "Unhandled Error" err="runtime/asm_amd64.s:1700: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.59.100:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&resourceVersion=14299\": net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.666261       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: statefulsets.apps is forbidden: User \"system:kube-scheduler\" cannot watch resource \"statefulsets\" in API group \"apps\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.675307       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.VolumeAttachment: volumeattachments.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot watch resource \"volumeattachments\" in API group \"storage.k8s.io\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.696372       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot watch resource \"storageclasses\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError"
E0215 14:52:33.706034       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot watch resource \"csinodes\" in API group \"storage.k8s.io\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.722179       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: services is forbidden: User \"system:kube-scheduler\" cannot watch resource \"services\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.762031       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: nodes is forbidden: User \"system:kube-scheduler\" cannot watch resource \"nodes\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.791437       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: replicasets.apps is forbidden: User \"system:kube-scheduler\" cannot watch resource \"replicasets\" in API group \"apps\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.802128       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: replicationcontrollers is forbidden: User \"system:kube-scheduler\" cannot watch resource \"replicationcontrollers\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.802411       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: persistentvolumes is forbidden: User \"system:kube-scheduler\" cannot watch resource \"persistentvolumes\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:33.776254       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot watch resource \"namespaces\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:34.302274       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User \"system:kube-scheduler\" cannot watch resource \"persistentvolumeclaims\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:34.419062       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: pods is forbidden: User \"system:kube-scheduler\" cannot watch resource \"pods\" in API group \"\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:34.429113       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \"system:kube-scheduler\" cannot watch resource \"poddisruptionbudgets\" in API group \"policy\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:34.429902       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot watch resource \"csistoragecapacities\" in API group \"storage.k8s.io\" at the cluster scope - error from a previous attempt: net/http: TLS handshake timeout" logger="UnhandledError"
E0215 14:52:34.430304       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot watch resource \"csidrivers\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError"


==> kubelet <==
Mar 12 13:22:10 minikube kubelet[1552]: E0312 13:22:10.602451    1552 log.go:32] "ContainerStatus from runtime service failed" err="rpc error: code = Unknown desc = Error response from daemon: No such container: 1cb385230c8e6c9340f4bd658e22d3dd004f214f21ea402ccf922b1d6b0dc5ff" containerID="1cb385230c8e6c9340f4bd658e22d3dd004f214f21ea402ccf922b1d6b0dc5ff"
Mar 12 13:22:10 minikube kubelet[1552]: E0312 13:22:10.606136    1552 kuberuntime_manager.go:1666] "getPodContainerStatuses for pod failed" err="rpc error: code = Unknown desc = Error response from daemon: No such container: 1cb385230c8e6c9340f4bd658e22d3dd004f214f21ea402ccf922b1d6b0dc5ff" pod="kube-system/storage-provisioner"
Mar 12 13:22:10 minikube kubelet[1552]: E0312 13:22:10.623401    1552 generic.go:459] "PLEG: Write status" err="rpc error: code = Unknown desc = Error response from daemon: No such container: 1cb385230c8e6c9340f4bd658e22d3dd004f214f21ea402ccf922b1d6b0dc5ff" pod="kube-system/storage-provisioner"
Mar 12 13:22:10 minikube kubelet[1552]: E0312 13:22:10.623581    1552 generic.go:302] "PLEG: Ignoring events for pod" err="rpc error: code = Unknown desc = Error response from daemon: No such container: 1cb385230c8e6c9340f4bd658e22d3dd004f214f21ea402ccf922b1d6b0dc5ff" pod="kube-system/storage-provisioner"
Mar 12 13:23:04 minikube kubelet[1552]: E0312 13:23:04.694812    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:23:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:23:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:23:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:23:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:23:32 minikube kubelet[1552]: E0312 13:23:32.881251    1552 secret.go:189] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Mar 12 13:23:32 minikube kubelet[1552]: E0312 13:23:32.889214    1552 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert podName:823e97f6-a374-4f61-a0e6-a019bbf74abe nodeName:}" failed. No retries permitted until 2025-03-12 13:25:34.88908051 +0000 UTC m=+5015.810315591 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert") pod "ingress-nginx-controller-56d7c84fd4-c92rw" (UID: "823e97f6-a374-4f61-a0e6-a019bbf74abe") : secret "ingress-nginx-admission" not found
Mar 12 13:24:04 minikube kubelet[1552]: E0312 13:24:04.537850    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:24:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:24:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:24:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:24:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:24:21 minikube kubelet[1552]: E0312 13:24:21.771650    1552 pod_workers.go:1301] "Error syncing pod, skipping" err="unmounted volumes=[webhook-cert], unattached volumes=[], failed to process volumes=[]: context deadline exceeded" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-c92rw" podUID="823e97f6-a374-4f61-a0e6-a019bbf74abe"
Mar 12 13:25:04 minikube kubelet[1552]: E0312 13:25:04.542605    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:25:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:25:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:25:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:25:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:25:34 minikube kubelet[1552]: E0312 13:25:34.947595    1552 secret.go:189] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Mar 12 13:25:34 minikube kubelet[1552]: E0312 13:25:34.971597    1552 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert podName:823e97f6-a374-4f61-a0e6-a019bbf74abe nodeName:}" failed. No retries permitted until 2025-03-12 13:27:36.960631071 +0000 UTC m=+5137.881866149 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert") pod "ingress-nginx-controller-56d7c84fd4-c92rw" (UID: "823e97f6-a374-4f61-a0e6-a019bbf74abe") : secret "ingress-nginx-admission" not found
Mar 12 13:26:04 minikube kubelet[1552]: E0312 13:26:04.544356    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:26:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:26:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:26:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:26:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:26:37 minikube kubelet[1552]: E0312 13:26:37.764846    1552 pod_workers.go:1301] "Error syncing pod, skipping" err="unmounted volumes=[webhook-cert], unattached volumes=[], failed to process volumes=[]: context deadline exceeded" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-c92rw" podUID="823e97f6-a374-4f61-a0e6-a019bbf74abe"
Mar 12 13:27:04 minikube kubelet[1552]: E0312 13:27:04.572989    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:27:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:27:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:27:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:27:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:27:36 minikube kubelet[1552]: E0312 13:27:36.967014    1552 secret.go:189] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Mar 12 13:27:36 minikube kubelet[1552]: E0312 13:27:36.982412    1552 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert podName:823e97f6-a374-4f61-a0e6-a019bbf74abe nodeName:}" failed. No retries permitted until 2025-03-12 13:29:38.982193111 +0000 UTC m=+5259.903428175 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert") pod "ingress-nginx-controller-56d7c84fd4-c92rw" (UID: "823e97f6-a374-4f61-a0e6-a019bbf74abe") : secret "ingress-nginx-admission" not found
Mar 12 13:28:04 minikube kubelet[1552]: E0312 13:28:04.618906    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:28:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:28:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:28:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:28:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:28:54 minikube kubelet[1552]: E0312 13:28:54.791558    1552 pod_workers.go:1301] "Error syncing pod, skipping" err="unmounted volumes=[webhook-cert], unattached volumes=[], failed to process volumes=[]: context deadline exceeded" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-c92rw" podUID="823e97f6-a374-4f61-a0e6-a019bbf74abe"
Mar 12 13:29:04 minikube kubelet[1552]: E0312 13:29:04.596863    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:29:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:29:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:29:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:29:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:29:39 minikube kubelet[1552]: E0312 13:29:39.074016    1552 secret.go:189] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Mar 12 13:29:39 minikube kubelet[1552]: E0312 13:29:39.075753    1552 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert podName:823e97f6-a374-4f61-a0e6-a019bbf74abe nodeName:}" failed. No retries permitted until 2025-03-12 13:31:41.075252228 +0000 UTC m=+5381.996487321 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/823e97f6-a374-4f61-a0e6-a019bbf74abe-webhook-cert") pod "ingress-nginx-controller-56d7c84fd4-c92rw" (UID: "823e97f6-a374-4f61-a0e6-a019bbf74abe") : secret "ingress-nginx-admission" not found
Mar 12 13:30:04 minikube kubelet[1552]: E0312 13:30:04.663642    1552 iptables.go:577] "Could not set up iptables canary" err=<
Mar 12 13:30:04 minikube kubelet[1552]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: Ignoring deprecated --wait-interval option.
Mar 12 13:30:04 minikube kubelet[1552]:         ip6tables v1.8.9 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Mar 12 13:30:04 minikube kubelet[1552]:         Perhaps ip6tables or your kernel needs to be upgraded.
Mar 12 13:30:04 minikube kubelet[1552]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Mar 12 13:30:17 minikube kubelet[1552]: E0312 13:30:17.129266    1552 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.359s"
Mar 12 13:30:18 minikube kubelet[1552]: E0312 13:30:18.782554    1552 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.023s"
Mar 12 13:30:31 minikube kubelet[1552]: E0312 13:30:31.873742    1552 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="2.111s"
Mar 12 13:30:32 minikube kubelet[1552]: E0312 13:30:32.930891    1552 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.052s"
Mar 12 13:30:39 minikube kubelet[1552]: E0312 13:30:39.392959    1552 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.634s"


==> storage-provisioner [205013e30d88] <==
k8s.io/apimachinery/pkg/runtime/serializer/streaming.(*decoder).Decode(0xc0003b3900, 0x0, 0x18bc168, 0xc0001e8100, 0x0, 0x0, 0x461dc0, 0xc000082b40, 0xc0004b5e50)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/runtime/serializer/streaming/streaming.go:77 +0x89
k8s.io/client-go/rest/watch.(*Decoder).Decode(0xc00001ee40, 0xc0004b5ef0, 0x8, 0x18bbba0, 0xc0004f4600, 0x0, 0x0)
	/Users/medya/go/pkg/mod/k8s.io/client-go@v0.20.5/rest/watch/decoder.go:49 +0x6e
k8s.io/apimachinery/pkg/watch.(*StreamWatcher).receive(0xc0001e8940)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:104 +0x14a
created by k8s.io/apimachinery/pkg/watch.NewStreamWatcher
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:71 +0xbe

goroutine 471 [sync.Cond.Wait]:
sync.runtime_notifyListWait(0xc0004db0c0, 0x4)
	/usr/local/go/src/runtime/sema.go:513 +0xf8
sync.(*Cond).Wait(0xc0004db0b0)
	/usr/local/go/src/sync/cond.go:56 +0x99
golang.org/x/net/http2.(*pipe).Read(0xc0004db0a8, 0xc000541801, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/pipe.go:65 +0x97
golang.org/x/net/http2.transportResponseBody.Read(0xc0004db080, 0xc000541801, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/transport.go:2108 +0xaf
encoding/json.(*Decoder).refill(0xc0004db340, 0xa, 0x9)
	/usr/local/go/src/encoding/json/stream.go:165 +0xeb
encoding/json.(*Decoder).readValue(0xc0004db340, 0x0, 0x0, 0x152aee0)
	/usr/local/go/src/encoding/json/stream.go:140 +0x1ff
encoding/json.(*Decoder).Decode(0xc0004db340, 0x154a160, 0xc000329998, 0x203000, 0x203000)
	/usr/local/go/src/encoding/json/stream.go:63 +0x7c
k8s.io/apimachinery/pkg/util/framer.(*jsonFrameReader).Read(0xc0001e2cc0, 0xc00050a000, 0x400, 0x400, 0x40, 0x38, 0x15b0440)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/util/framer/framer.go:152 +0x1a8
k8s.io/apimachinery/pkg/runtime/serializer/streaming.(*decoder).Decode(0xc000353540, 0x0, 0x18bc168, 0xc000022600, 0x0, 0x0, 0x461dc0, 0xc00049c8a0, 0xc000065e50)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/runtime/serializer/streaming/streaming.go:77 +0x89
k8s.io/client-go/rest/watch.(*Decoder).Decode(0xc00001f9a0, 0xc000065ef0, 0x8, 0x18baa20, 0xc000128000, 0x0, 0x0)
	/Users/medya/go/pkg/mod/k8s.io/client-go@v0.20.5/rest/watch/decoder.go:49 +0x6e
k8s.io/apimachinery/pkg/watch.(*StreamWatcher).receive(0xc0001e9540)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:104 +0x14a
created by k8s.io/apimachinery/pkg/watch.NewStreamWatcher
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:71 +0xbe

goroutine 659 [sync.Cond.Wait]:
sync.runtime_notifyListWait(0xc0002e9640, 0x1)
	/usr/local/go/src/runtime/sema.go:513 +0xf8
sync.(*Cond).Wait(0xc0002e9630)
	/usr/local/go/src/sync/cond.go:56 +0x99
golang.org/x/net/http2.(*pipe).Read(0xc0002e9628, 0xc000540c01, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/pipe.go:65 +0x97
golang.org/x/net/http2.transportResponseBody.Read(0xc0002e9600, 0xc000540c01, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/transport.go:2108 +0xaf
encoding/json.(*Decoder).refill(0xc0002e98c0, 0xa, 0x9)
	/usr/local/go/src/encoding/json/stream.go:165 +0xeb
encoding/json.(*Decoder).readValue(0xc0002e98c0, 0x0, 0x0, 0x152aee0)
	/usr/local/go/src/encoding/json/stream.go:140 +0x1ff
encoding/json.(*Decoder).Decode(0xc0002e98c0, 0x154a160, 0xc000329368, 0x203000, 0x203000)
	/usr/local/go/src/encoding/json/stream.go:63 +0x7c
k8s.io/apimachinery/pkg/util/framer.(*jsonFrameReader).Read(0xc000368ae0, 0xc00050b800, 0x400, 0x400, 0x40, 0x38, 0x15b0440)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/util/framer/framer.go:152 +0x1a8
k8s.io/apimachinery/pkg/runtime/serializer/streaming.(*decoder).Decode(0xc0003b2280, 0x0, 0x18bc168, 0xc000022340, 0x0, 0x0, 0x461dc0, 0xc000083e60, 0xc0005f1e50)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/runtime/serializer/streaming/streaming.go:77 +0x89
k8s.io/client-go/rest/watch.(*Decoder).Decode(0xc00015b580, 0xc0005f1ef0, 0x8, 0x18baa48, 0xc0004521c0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/k8s.io/client-go@v0.20.5/rest/watch/decoder.go:49 +0x6e
k8s.io/apimachinery/pkg/watch.(*StreamWatcher).receive(0xc0001e8d80)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:104 +0x14a
created by k8s.io/apimachinery/pkg/watch.NewStreamWatcher
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:71 +0xbe


==> storage-provisioner [9ecc603e6630] <==
I0312 13:22:11.259031       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0312 13:22:11.681446       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0312 13:22:11.696136       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0312 13:22:29.558027       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0312 13:22:29.563254       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_622bebfd-f782-4f2f-b6da-0850c76cfdbb!
I0312 13:22:29.619431       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"85927da2-cbd4-4219-9fff-2671ee1ad8a8", APIVersion:"v1", ResourceVersion:"29932", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_622bebfd-f782-4f2f-b6da-0850c76cfdbb became leader
I0312 13:22:30.163992       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_622bebfd-f782-4f2f-b6da-0850c76cfdbb!

